{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff2cee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This file contains the pipeline for training and evaluating the GCN on the data.\"\"\"\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from typeguard import typechecked\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"/home/jovyan/20230406_ArticleClassifier/ArticleClassifier\")\n",
    "\n",
    "import src.general.global_variables as gv\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname('data_loader.py'), os.path.pardir)))\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.data_processing import standardise_embeddings\n",
    "\n",
    "from src.general.utils import cc_path\n",
    "from src.models.evaluation import Metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4330fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Start loading data...')\n",
    "loc_dict = {\n",
    "    'processed_csv': cc_path('data/processed/canary/articles_cleaned.csv'),\n",
    "    'abstract_embeddings': cc_path('data/processed/canary/embeddings_fasttext_20230410.csv'),\n",
    "    'scibert_embeddings': cc_path('data/processed/canary/embeddings_scibert_20230413.csv'),\n",
    "    'keyword_network': cc_path('data/processed/canary/keyword_network_weighted.pickle'),\n",
    "    'xml_embeddings': cc_path('data/processed/canary/embeddings_xml.ftr'),\n",
    "    'author_network': cc_path('data/processed/canary/author_network.pickle'), \n",
    "    'label_network': cc_path('data/processed/canary/label_network_weighted.pickle')\n",
    "}\n",
    "data_loader = DataLoader(loc_dict)\n",
    "processed_df = data_loader.load_processed_csv()\n",
    "embedding_df = data_loader.load_embeddings_csv()\n",
    "embedding_df = standardise_embeddings(embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb59a191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pui</th>\n",
       "      <th>d0</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>...</th>\n",
       "      <th>d246</th>\n",
       "      <th>d247</th>\n",
       "      <th>d248</th>\n",
       "      <th>d249</th>\n",
       "      <th>d250</th>\n",
       "      <th>d251</th>\n",
       "      <th>d252</th>\n",
       "      <th>d253</th>\n",
       "      <th>d254</th>\n",
       "      <th>d255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624531411</td>\n",
       "      <td>0.523307</td>\n",
       "      <td>1.438530</td>\n",
       "      <td>-0.080917</td>\n",
       "      <td>-0.187375</td>\n",
       "      <td>0.072302</td>\n",
       "      <td>-1.583681</td>\n",
       "      <td>0.250296</td>\n",
       "      <td>0.900716</td>\n",
       "      <td>-0.741329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135713</td>\n",
       "      <td>-0.404753</td>\n",
       "      <td>0.530738</td>\n",
       "      <td>-1.523115</td>\n",
       "      <td>-0.309949</td>\n",
       "      <td>-0.956836</td>\n",
       "      <td>0.191369</td>\n",
       "      <td>-0.745007</td>\n",
       "      <td>1.264909</td>\n",
       "      <td>1.375934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625340088</td>\n",
       "      <td>0.453272</td>\n",
       "      <td>1.137349</td>\n",
       "      <td>-1.342064</td>\n",
       "      <td>0.234267</td>\n",
       "      <td>1.387469</td>\n",
       "      <td>1.169491</td>\n",
       "      <td>0.813650</td>\n",
       "      <td>0.410952</td>\n",
       "      <td>-0.195154</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427820</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>-0.211770</td>\n",
       "      <td>-1.288424</td>\n",
       "      <td>0.660130</td>\n",
       "      <td>-2.610597</td>\n",
       "      <td>1.132445</td>\n",
       "      <td>2.322045</td>\n",
       "      <td>0.469497</td>\n",
       "      <td>1.136931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625805682</td>\n",
       "      <td>-0.059067</td>\n",
       "      <td>0.170448</td>\n",
       "      <td>-0.223014</td>\n",
       "      <td>0.705250</td>\n",
       "      <td>1.362661</td>\n",
       "      <td>-1.334532</td>\n",
       "      <td>-0.514577</td>\n",
       "      <td>0.166644</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918942</td>\n",
       "      <td>0.827185</td>\n",
       "      <td>-0.775148</td>\n",
       "      <td>-1.769286</td>\n",
       "      <td>0.425720</td>\n",
       "      <td>-1.537911</td>\n",
       "      <td>0.914770</td>\n",
       "      <td>0.827428</td>\n",
       "      <td>1.122793</td>\n",
       "      <td>1.136876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626662493</td>\n",
       "      <td>0.331264</td>\n",
       "      <td>-0.128117</td>\n",
       "      <td>-2.104888</td>\n",
       "      <td>0.236542</td>\n",
       "      <td>1.049195</td>\n",
       "      <td>1.514864</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>-1.626433</td>\n",
       "      <td>0.648361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014593</td>\n",
       "      <td>-1.935730</td>\n",
       "      <td>0.909682</td>\n",
       "      <td>-0.389697</td>\n",
       "      <td>1.338018</td>\n",
       "      <td>-0.443178</td>\n",
       "      <td>0.641751</td>\n",
       "      <td>-0.139190</td>\n",
       "      <td>-1.298358</td>\n",
       "      <td>0.807388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>626822402</td>\n",
       "      <td>-0.288815</td>\n",
       "      <td>-1.844490</td>\n",
       "      <td>0.028553</td>\n",
       "      <td>1.893139</td>\n",
       "      <td>-0.935294</td>\n",
       "      <td>1.106734</td>\n",
       "      <td>-1.491607</td>\n",
       "      <td>-0.352630</td>\n",
       "      <td>-0.468991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.670850</td>\n",
       "      <td>0.319826</td>\n",
       "      <td>-0.376360</td>\n",
       "      <td>-0.205706</td>\n",
       "      <td>-1.133871</td>\n",
       "      <td>-0.471493</td>\n",
       "      <td>-0.035112</td>\n",
       "      <td>0.090738</td>\n",
       "      <td>0.177633</td>\n",
       "      <td>-1.315776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117305</th>\n",
       "      <td>2011621972</td>\n",
       "      <td>0.410056</td>\n",
       "      <td>-0.997743</td>\n",
       "      <td>0.753250</td>\n",
       "      <td>-0.983777</td>\n",
       "      <td>-1.308745</td>\n",
       "      <td>0.268359</td>\n",
       "      <td>-0.362296</td>\n",
       "      <td>1.848456</td>\n",
       "      <td>-1.967524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751787</td>\n",
       "      <td>1.455989</td>\n",
       "      <td>0.150169</td>\n",
       "      <td>0.588903</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.148446</td>\n",
       "      <td>1.444333</td>\n",
       "      <td>-0.515651</td>\n",
       "      <td>-0.118400</td>\n",
       "      <td>-0.185293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117306</th>\n",
       "      <td>2011622024</td>\n",
       "      <td>1.088784</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>1.156794</td>\n",
       "      <td>-0.696836</td>\n",
       "      <td>0.203408</td>\n",
       "      <td>0.937699</td>\n",
       "      <td>0.986402</td>\n",
       "      <td>2.081369</td>\n",
       "      <td>-1.623275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612815</td>\n",
       "      <td>1.847444</td>\n",
       "      <td>-0.189883</td>\n",
       "      <td>1.228686</td>\n",
       "      <td>-0.223918</td>\n",
       "      <td>0.413490</td>\n",
       "      <td>1.540787</td>\n",
       "      <td>-1.583825</td>\n",
       "      <td>-1.793567</td>\n",
       "      <td>0.548181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117307</th>\n",
       "      <td>2011622065</td>\n",
       "      <td>0.157201</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.687774</td>\n",
       "      <td>0.356504</td>\n",
       "      <td>0.275766</td>\n",
       "      <td>-1.527228</td>\n",
       "      <td>0.734882</td>\n",
       "      <td>-0.341372</td>\n",
       "      <td>0.323361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522548</td>\n",
       "      <td>-0.694288</td>\n",
       "      <td>-1.353055</td>\n",
       "      <td>0.980701</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>-0.653802</td>\n",
       "      <td>-0.842045</td>\n",
       "      <td>-0.416620</td>\n",
       "      <td>0.845871</td>\n",
       "      <td>0.409172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117308</th>\n",
       "      <td>2011626864</td>\n",
       "      <td>-1.163109</td>\n",
       "      <td>-0.616085</td>\n",
       "      <td>0.716920</td>\n",
       "      <td>0.693161</td>\n",
       "      <td>-0.796137</td>\n",
       "      <td>1.830795</td>\n",
       "      <td>-0.697601</td>\n",
       "      <td>-0.946027</td>\n",
       "      <td>-0.068566</td>\n",
       "      <td>...</td>\n",
       "      <td>1.553166</td>\n",
       "      <td>1.017975</td>\n",
       "      <td>0.491364</td>\n",
       "      <td>1.343349</td>\n",
       "      <td>-1.649031</td>\n",
       "      <td>1.036480</td>\n",
       "      <td>-0.450476</td>\n",
       "      <td>-1.386962</td>\n",
       "      <td>-0.871713</td>\n",
       "      <td>-1.482193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117309</th>\n",
       "      <td>2011632199</td>\n",
       "      <td>-0.807586</td>\n",
       "      <td>-1.128502</td>\n",
       "      <td>1.464045</td>\n",
       "      <td>-0.207904</td>\n",
       "      <td>-2.023682</td>\n",
       "      <td>-0.017909</td>\n",
       "      <td>-0.649002</td>\n",
       "      <td>0.802553</td>\n",
       "      <td>-0.075851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662071</td>\n",
       "      <td>0.813970</td>\n",
       "      <td>0.492810</td>\n",
       "      <td>0.194973</td>\n",
       "      <td>0.066882</td>\n",
       "      <td>-0.623779</td>\n",
       "      <td>1.558891</td>\n",
       "      <td>-0.123211</td>\n",
       "      <td>0.714357</td>\n",
       "      <td>-0.299161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117310 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pui        d0        d1        d2        d3        d4   \n",
       "0        624531411  0.523307  1.438530 -0.080917 -0.187375  0.072302  \\\n",
       "1        625340088  0.453272  1.137349 -1.342064  0.234267  1.387469   \n",
       "2        625805682 -0.059067  0.170448 -0.223014  0.705250  1.362661   \n",
       "3        626662493  0.331264 -0.128117 -2.104888  0.236542  1.049195   \n",
       "4        626822402 -0.288815 -1.844490  0.028553  1.893139 -0.935294   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "117305  2011621972  0.410056 -0.997743  0.753250 -0.983777 -1.308745   \n",
       "117306  2011622024  1.088784  0.015001  1.156794 -0.696836  0.203408   \n",
       "117307  2011622065  0.157201  0.386948  0.687774  0.356504  0.275766   \n",
       "117308  2011626864 -1.163109 -0.616085  0.716920  0.693161 -0.796137   \n",
       "117309  2011632199 -0.807586 -1.128502  1.464045 -0.207904 -2.023682   \n",
       "\n",
       "              d5        d6        d7        d8  ...      d246      d247   \n",
       "0      -1.583681  0.250296  0.900716 -0.741329  ... -0.135713 -0.404753  \\\n",
       "1       1.169491  0.813650  0.410952 -0.195154  ... -1.427820  0.143418   \n",
       "2      -1.334532 -0.514577  0.166644 -0.142857  ... -0.918942  0.827185   \n",
       "3       1.514864  0.991066 -1.626433  0.648361  ... -0.014593 -1.935730   \n",
       "4       1.106734 -1.491607 -0.352630 -0.468991  ...  1.670850  0.319826   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "117305  0.268359 -0.362296  1.848456 -1.967524  ...  0.751787  1.455989   \n",
       "117306  0.937699  0.986402  2.081369 -1.623275  ...  0.612815  1.847444   \n",
       "117307 -1.527228  0.734882 -0.341372  0.323361  ... -0.522548 -0.694288   \n",
       "117308  1.830795 -0.697601 -0.946027 -0.068566  ...  1.553166  1.017975   \n",
       "117309 -0.017909 -0.649002  0.802553 -0.075851  ...  0.662071  0.813970   \n",
       "\n",
       "            d248      d249      d250      d251      d252      d253      d254   \n",
       "0       0.530738 -1.523115 -0.309949 -0.956836  0.191369 -0.745007  1.264909  \\\n",
       "1      -0.211770 -1.288424  0.660130 -2.610597  1.132445  2.322045  0.469497   \n",
       "2      -0.775148 -1.769286  0.425720 -1.537911  0.914770  0.827428  1.122793   \n",
       "3       0.909682 -0.389697  1.338018 -0.443178  0.641751 -0.139190 -1.298358   \n",
       "4      -0.376360 -0.205706 -1.133871 -0.471493 -0.035112  0.090738  0.177633   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "117305  0.150169  0.588903  0.036674  0.148446  1.444333 -0.515651 -0.118400   \n",
       "117306 -0.189883  1.228686 -0.223918  0.413490  1.540787 -1.583825 -1.793567   \n",
       "117307 -1.353055  0.980701 -0.020913 -0.653802 -0.842045 -0.416620  0.845871   \n",
       "117308  0.491364  1.343349 -1.649031  1.036480 -0.450476 -1.386962 -0.871713   \n",
       "117309  0.492810  0.194973  0.066882 -0.623779  1.558891 -0.123211  0.714357   \n",
       "\n",
       "            d255  \n",
       "0       1.375934  \n",
       "1       1.136931  \n",
       "2       1.136876  \n",
       "3       0.807388  \n",
       "4      -1.315776  \n",
       "...          ...  \n",
       "117305 -0.185293  \n",
       "117306  0.548181  \n",
       "117307  0.409172  \n",
       "117308 -1.482193  \n",
       "117309 -0.299161  \n",
       "\n",
       "[117310 rows x 257 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa59a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4434/1349467975.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_columns[label_columns.columns.difference(['pui'])] = label_columns[\n"
     ]
    }
   ],
   "source": [
    "label_columns = processed_df.loc[:, ~processed_df.columns.isin(\n",
    "    ['file_name', 'title', 'keywords', 'abstract', 'abstract_2', 'authors', 'organization', 'chemicals',\n",
    "     'num_refs', 'date-delivered', 'labels_m', 'labels_a'])]\n",
    "\n",
    "# label_columns = processed_df.loc[:, ['pui', 'human', 'mouse', 'rat', 'nonhuman',\n",
    "#                                      'controlled study', 'animal experiment']]\n",
    "label_columns[label_columns.columns.difference(['pui'])] = label_columns[\n",
    "    label_columns.columns.difference(['pui'])].astype(int)\n",
    "features = ['file_name', 'pui', 'title', 'keywords', 'abstract', 'abstract_2', 'authors', 'organization',\n",
    "            'chemicals',\n",
    "            'num_refs', 'date-delivered', 'labels_m', 'labels_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81a9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cc_path(\"data/pui_idx_mapping.json\"), \"r\") as outfile:\n",
    "    node_label_mapping = json.load(outfile)\n",
    "    \n",
    "with open(cc_path(f'data/train_indices.txt')) as f:\n",
    "    train_puis = f.read().splitlines()\n",
    "    train_indices = list(map(node_label_mapping.get, train_puis))\n",
    "with open(cc_path(f'data/val_indices.txt')) as f:\n",
    "    val_puis = f.read().splitlines()\n",
    "    val_indices = list(map(node_label_mapping.get, val_puis))\n",
    "with open(cc_path(f'data/test_indices.txt')) as f:\n",
    "    test_puis = f.read().splitlines()\n",
    "    test_indices = list(map(node_label_mapping.get, test_puis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36995bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df.set_index('pui', inplace=True)\n",
    "label_columns.set_index('pui', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2edc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_df = embedding_df.loc[train_puis]\n",
    "train_texts = train_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "train_labels = label_columns.loc[train_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n",
    "\n",
    "val_texts_df = embedding_df.loc[val_puis]\n",
    "val_texts = val_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "val_labels = label_columns.loc[val_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n",
    "\n",
    "test_texts_df = embedding_df.loc[test_puis]\n",
    "test_texts = test_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "test_labels = label_columns.loc[test_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288da2b",
   "metadata": {},
   "source": [
    "## Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ddcab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62e052ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "ovr = OneVsRestClassifier(lr, n_jobs=-11)\n",
    "ovr.fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e61240b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = ovr.predict(train_texts)\n",
    "y_val_preds = ovr.predict(val_texts)\n",
    "y_test_preds = ovr.predict(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82b54b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: macro - f1_score: 0.47038260268676846\n",
      "train: micro - f1_score: 0.7322604838287705\n",
      "train: macro - recall: 0.40230362198115394\n",
      "train: micro - recall: 0.6778775255379382\n",
      "train: macro - precision: 0.7065758261506867\n",
      "train: micro - precision: 0.7961303127607393\n",
      "val: macro - f1_score: 0.39366005045413444\n",
      "val: micro - f1_score: 0.7222428863678632\n",
      "val: macro - recall: 0.3414371083815635\n",
      "val: micro - recall: 0.6675834801667454\n",
      "val: macro - precision: 0.5426066073272986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/articleclassifier/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: micro - precision: 0.7866511368815516\n",
      "test: macro - f1_score: 0.44110422298635804\n",
      "test: micro - f1_score: 0.729988552921797\n",
      "test: macro - recall: 0.37869912718318527\n",
      "test: micro - recall: 0.6738544011271284\n",
      "test: macro - precision: 0.6348763728404164\n",
      "test: micro - precision: 0.7963248730964467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "for dataset_name, (dataset_pred, dataset_real) in {'train': (y_train_preds, train_labels), 'val': (y_val_preds, val_labels), 'test': (y_test_preds, test_labels)}.items():\n",
    "    for metric_name, metric in {'f1_score': f1_score, 'recall': recall_score, 'precision': precision_score}.items():\n",
    "        for averaging_type in ['macro', 'micro']:\n",
    "            print(f'{dataset_name}: {averaging_type} - {metric_name}: {metric(dataset_real, dataset_pred, average=averaging_type)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dadc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-articleclassifier [Python]",
   "language": "python",
   "name": "conda-env-.conda-articleclassifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
