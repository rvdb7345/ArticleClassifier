{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2cee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This file contains the pipeline for training and evaluating the GCN on the data.\"\"\"\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from typeguard import typechecked\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"/home/jovyan/20230406_ArticleClassifier/ArticleClassifier\")\n",
    "\n",
    "import src.general.global_variables as gv\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname('data_loader.py'), os.path.pardir)))\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.data_processing import standardise_embeddings\n",
    "\n",
    "from src.general.utils import cc_path\n",
    "from src.models.evaluation import Metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4330fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Start loading data...')\n",
    "loc_dict = {\n",
    "    'processed_csv': cc_path('data/processed/canary/articles_cleaned.csv'),\n",
    "    'abstract_embeddings': cc_path('data/processed/canary/embeddings_fasttext_20230410.csv'),\n",
    "    'scibert_embeddings': cc_path('data/processed/canary/embeddings_scibert_20230413.csv'),\n",
    "    'keyword_network': cc_path('data/processed/canary/keyword_network_weighted.pickle'),\n",
    "    'xml_embeddings': cc_path('data/processed/canary/embeddings_xml.ftr'),\n",
    "    'author_network': cc_path('data/processed/canary/author_network.pickle'), \n",
    "    'label_network': cc_path('data/processed/canary/label_network_weighted.pickle')\n",
    "}\n",
    "data_loader = DataLoader(loc_dict)\n",
    "processed_df = data_loader.load_processed_csv()\n",
    "embedding_df = data_loader.load_scibert_embeddings_csv()\n",
    "embedding_df = standardise_embeddings(embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb59a191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pui</th>\n",
       "      <th>d0</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>...</th>\n",
       "      <th>d758</th>\n",
       "      <th>d759</th>\n",
       "      <th>d760</th>\n",
       "      <th>d761</th>\n",
       "      <th>d762</th>\n",
       "      <th>d763</th>\n",
       "      <th>d764</th>\n",
       "      <th>d765</th>\n",
       "      <th>d766</th>\n",
       "      <th>d767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624531411</td>\n",
       "      <td>1.724949</td>\n",
       "      <td>-0.962311</td>\n",
       "      <td>-0.916890</td>\n",
       "      <td>-3.019909</td>\n",
       "      <td>1.156869</td>\n",
       "      <td>0.775545</td>\n",
       "      <td>1.696071</td>\n",
       "      <td>1.341233</td>\n",
       "      <td>-0.070411</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.360899</td>\n",
       "      <td>0.901550</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>0.728343</td>\n",
       "      <td>-2.005042</td>\n",
       "      <td>0.101287</td>\n",
       "      <td>-0.038096</td>\n",
       "      <td>0.202163</td>\n",
       "      <td>1.430674</td>\n",
       "      <td>0.079277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625340088</td>\n",
       "      <td>0.554961</td>\n",
       "      <td>3.080485</td>\n",
       "      <td>-0.729940</td>\n",
       "      <td>-1.055520</td>\n",
       "      <td>0.941503</td>\n",
       "      <td>0.080624</td>\n",
       "      <td>-0.799699</td>\n",
       "      <td>-0.848227</td>\n",
       "      <td>3.005049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328036</td>\n",
       "      <td>-0.011042</td>\n",
       "      <td>0.460629</td>\n",
       "      <td>-0.703980</td>\n",
       "      <td>-1.130742</td>\n",
       "      <td>-3.013882</td>\n",
       "      <td>0.546458</td>\n",
       "      <td>0.892324</td>\n",
       "      <td>0.747129</td>\n",
       "      <td>0.086044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625805682</td>\n",
       "      <td>0.565920</td>\n",
       "      <td>3.867995</td>\n",
       "      <td>0.258198</td>\n",
       "      <td>-1.007153</td>\n",
       "      <td>-0.205592</td>\n",
       "      <td>1.003677</td>\n",
       "      <td>-2.211239</td>\n",
       "      <td>-0.545270</td>\n",
       "      <td>1.809024</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.104570</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>1.243758</td>\n",
       "      <td>-0.784265</td>\n",
       "      <td>-2.496688</td>\n",
       "      <td>-0.386428</td>\n",
       "      <td>0.316321</td>\n",
       "      <td>1.064401</td>\n",
       "      <td>2.162855</td>\n",
       "      <td>0.974458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626662493</td>\n",
       "      <td>0.589574</td>\n",
       "      <td>0.171245</td>\n",
       "      <td>-0.374974</td>\n",
       "      <td>1.760145</td>\n",
       "      <td>0.714378</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>0.642225</td>\n",
       "      <td>-0.603529</td>\n",
       "      <td>1.615703</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143460</td>\n",
       "      <td>-0.499742</td>\n",
       "      <td>1.147708</td>\n",
       "      <td>0.905595</td>\n",
       "      <td>0.196390</td>\n",
       "      <td>-1.750528</td>\n",
       "      <td>0.834781</td>\n",
       "      <td>0.664159</td>\n",
       "      <td>2.008654</td>\n",
       "      <td>1.673547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>626822402</td>\n",
       "      <td>0.765471</td>\n",
       "      <td>-0.337877</td>\n",
       "      <td>-0.183119</td>\n",
       "      <td>-0.232586</td>\n",
       "      <td>-0.986672</td>\n",
       "      <td>-0.270002</td>\n",
       "      <td>1.486768</td>\n",
       "      <td>-0.785418</td>\n",
       "      <td>-1.257400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043334</td>\n",
       "      <td>-0.751844</td>\n",
       "      <td>-0.779597</td>\n",
       "      <td>1.890243</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>-0.869973</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.288078</td>\n",
       "      <td>-0.007600</td>\n",
       "      <td>0.244727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117305</th>\n",
       "      <td>2011621972</td>\n",
       "      <td>-0.933348</td>\n",
       "      <td>1.521798</td>\n",
       "      <td>0.592468</td>\n",
       "      <td>-0.353155</td>\n",
       "      <td>-0.483301</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>0.649759</td>\n",
       "      <td>-1.882091</td>\n",
       "      <td>-0.287263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.090271</td>\n",
       "      <td>-0.482317</td>\n",
       "      <td>-1.637399</td>\n",
       "      <td>0.483649</td>\n",
       "      <td>0.212784</td>\n",
       "      <td>0.961884</td>\n",
       "      <td>0.871724</td>\n",
       "      <td>-0.340540</td>\n",
       "      <td>0.512850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117306</th>\n",
       "      <td>2011622024</td>\n",
       "      <td>1.866118</td>\n",
       "      <td>-0.713270</td>\n",
       "      <td>-0.590325</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>-0.631587</td>\n",
       "      <td>-0.846515</td>\n",
       "      <td>-0.147998</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083385</td>\n",
       "      <td>-0.173565</td>\n",
       "      <td>-1.112911</td>\n",
       "      <td>-0.280100</td>\n",
       "      <td>-0.631747</td>\n",
       "      <td>0.541184</td>\n",
       "      <td>0.231767</td>\n",
       "      <td>-0.922456</td>\n",
       "      <td>-1.388049</td>\n",
       "      <td>0.522586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117307</th>\n",
       "      <td>2011622065</td>\n",
       "      <td>-1.387895</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.835669</td>\n",
       "      <td>0.365057</td>\n",
       "      <td>0.516104</td>\n",
       "      <td>0.495457</td>\n",
       "      <td>-0.712975</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.821042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.264139</td>\n",
       "      <td>-2.331056</td>\n",
       "      <td>-1.067966</td>\n",
       "      <td>0.212543</td>\n",
       "      <td>-0.124560</td>\n",
       "      <td>0.951281</td>\n",
       "      <td>-1.883171</td>\n",
       "      <td>-0.381497</td>\n",
       "      <td>0.123854</td>\n",
       "      <td>0.185559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117308</th>\n",
       "      <td>2011626864</td>\n",
       "      <td>0.349304</td>\n",
       "      <td>-1.349804</td>\n",
       "      <td>-0.876579</td>\n",
       "      <td>-0.755956</td>\n",
       "      <td>0.286240</td>\n",
       "      <td>-1.248593</td>\n",
       "      <td>0.818646</td>\n",
       "      <td>1.510866</td>\n",
       "      <td>-1.088184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>1.030749</td>\n",
       "      <td>-0.073069</td>\n",
       "      <td>0.362131</td>\n",
       "      <td>0.296715</td>\n",
       "      <td>-0.150970</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.234453</td>\n",
       "      <td>-0.739582</td>\n",
       "      <td>-0.459597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117309</th>\n",
       "      <td>2011632199</td>\n",
       "      <td>0.453621</td>\n",
       "      <td>0.404366</td>\n",
       "      <td>0.190980</td>\n",
       "      <td>-0.339089</td>\n",
       "      <td>-0.943122</td>\n",
       "      <td>-0.308677</td>\n",
       "      <td>0.885230</td>\n",
       "      <td>-0.600185</td>\n",
       "      <td>0.847275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626315</td>\n",
       "      <td>0.534478</td>\n",
       "      <td>0.572377</td>\n",
       "      <td>-0.381564</td>\n",
       "      <td>-0.321996</td>\n",
       "      <td>-0.920260</td>\n",
       "      <td>1.332181</td>\n",
       "      <td>-0.407073</td>\n",
       "      <td>-0.209649</td>\n",
       "      <td>0.274885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117310 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pui        d0        d1        d2        d3        d4   \n",
       "0        624531411  1.724949 -0.962311 -0.916890 -3.019909  1.156869  \\\n",
       "1        625340088  0.554961  3.080485 -0.729940 -1.055520  0.941503   \n",
       "2        625805682  0.565920  3.867995  0.258198 -1.007153 -0.205592   \n",
       "3        626662493  0.589574  0.171245 -0.374974  1.760145  0.714378   \n",
       "4        626822402  0.765471 -0.337877 -0.183119 -0.232586 -0.986672   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "117305  2011621972 -0.933348  1.521798  0.592468 -0.353155 -0.483301   \n",
       "117306  2011622024  1.866118 -0.713270 -0.590325  0.520996  0.698065   \n",
       "117307  2011622065 -1.387895  0.017300  0.835669  0.365057  0.516104   \n",
       "117308  2011626864  0.349304 -1.349804 -0.876579 -0.755956  0.286240   \n",
       "117309  2011632199  0.453621  0.404366  0.190980 -0.339089 -0.943122   \n",
       "\n",
       "              d5        d6        d7        d8  ...      d758      d759   \n",
       "0       0.775545  1.696071  1.341233 -0.070411  ... -2.360899  0.901550  \\\n",
       "1       0.080624 -0.799699 -0.848227  3.005049  ...  1.328036 -0.011042   \n",
       "2       1.003677 -2.211239 -0.545270  1.809024  ... -1.104570  0.165435   \n",
       "3      -0.054711  0.642225 -0.603529  1.615703  ...  2.143460 -0.499742   \n",
       "4      -0.270002  1.486768 -0.785418 -1.257400  ...  1.043334 -0.751844   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "117305  0.013271  0.649759 -1.882091 -0.287263  ...  0.379663  0.090271   \n",
       "117306 -0.631587 -0.846515 -0.147998  0.014351  ...  1.083385 -0.173565   \n",
       "117307  0.495457 -0.712975 -0.164661 -0.821042  ...  1.264139 -2.331056   \n",
       "117308 -1.248593  0.818646  1.510866 -1.088184  ...  0.399086  1.030749   \n",
       "117309 -0.308677  0.885230 -0.600185  0.847275  ... -0.626315  0.534478   \n",
       "\n",
       "            d760      d761      d762      d763      d764      d765      d766   \n",
       "0       0.111421  0.728343 -2.005042  0.101287 -0.038096  0.202163  1.430674  \\\n",
       "1       0.460629 -0.703980 -1.130742 -3.013882  0.546458  0.892324  0.747129   \n",
       "2       1.243758 -0.784265 -2.496688 -0.386428  0.316321  1.064401  2.162855   \n",
       "3       1.147708  0.905595  0.196390 -1.750528  0.834781  0.664159  2.008654   \n",
       "4      -0.779597  1.890243  0.497988 -0.869973  0.084734  0.288078 -0.007600   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "117305 -0.482317 -1.637399  0.483649  0.212784  0.961884  0.871724 -0.340540   \n",
       "117306 -1.112911 -0.280100 -0.631747  0.541184  0.231767 -0.922456 -1.388049   \n",
       "117307 -1.067966  0.212543 -0.124560  0.951281 -1.883171 -0.381497  0.123854   \n",
       "117308 -0.073069  0.362131  0.296715 -0.150970  0.633721  0.234453 -0.739582   \n",
       "117309  0.572377 -0.381564 -0.321996 -0.920260  1.332181 -0.407073 -0.209649   \n",
       "\n",
       "            d767  \n",
       "0       0.079277  \n",
       "1       0.086044  \n",
       "2       0.974458  \n",
       "3       1.673547  \n",
       "4       0.244727  \n",
       "...          ...  \n",
       "117305  0.512850  \n",
       "117306  0.522586  \n",
       "117307  0.185559  \n",
       "117308 -0.459597  \n",
       "117309  0.274885  \n",
       "\n",
       "[117310 rows x 769 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa59a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4016/1349467975.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_columns[label_columns.columns.difference(['pui'])] = label_columns[\n"
     ]
    }
   ],
   "source": [
    "label_columns = processed_df.loc[:, ~processed_df.columns.isin(\n",
    "    ['file_name', 'title', 'keywords', 'abstract', 'abstract_2', 'authors', 'organization', 'chemicals',\n",
    "     'num_refs', 'date-delivered', 'labels_m', 'labels_a'])]\n",
    "\n",
    "# label_columns = processed_df.loc[:, ['pui', 'human', 'mouse', 'rat', 'nonhuman',\n",
    "#                                      'controlled study', 'animal experiment']]\n",
    "label_columns[label_columns.columns.difference(['pui'])] = label_columns[\n",
    "    label_columns.columns.difference(['pui'])].astype(int)\n",
    "features = ['file_name', 'pui', 'title', 'keywords', 'abstract', 'abstract_2', 'authors', 'organization',\n",
    "            'chemicals',\n",
    "            'num_refs', 'date-delivered', 'labels_m', 'labels_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81a9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cc_path(\"data/pui_idx_mapping.json\"), \"r\") as outfile:\n",
    "    node_label_mapping = json.load(outfile)\n",
    "    \n",
    "with open(cc_path(f'data/train_indices.txt')) as f:\n",
    "    train_puis = f.read().splitlines()\n",
    "    train_indices = list(map(node_label_mapping.get, train_puis))\n",
    "with open(cc_path(f'data/val_indices.txt')) as f:\n",
    "    val_puis = f.read().splitlines()\n",
    "    val_indices = list(map(node_label_mapping.get, val_puis))\n",
    "with open(cc_path(f'data/test_indices.txt')) as f:\n",
    "    test_puis = f.read().splitlines()\n",
    "    test_indices = list(map(node_label_mapping.get, test_puis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36995bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df.set_index('pui', inplace=True)\n",
    "label_columns.set_index('pui', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2edc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_df = embedding_df.loc[train_puis]\n",
    "train_texts = train_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "train_labels = label_columns.loc[train_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n",
    "\n",
    "val_texts_df = embedding_df.loc[val_puis]\n",
    "val_texts = val_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "val_labels = label_columns.loc[val_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n",
    "\n",
    "test_texts_df = embedding_df.loc[test_puis]\n",
    "test_texts = test_texts_df[embedding_df.columns.difference(['pui'])].to_numpy()\n",
    "test_labels = label_columns.loc[test_texts_df.index.to_list(), label_columns.columns.difference(['pui'])].to_numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288da2b",
   "metadata": {},
   "source": [
    "## Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddcab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62e052ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000), n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000), n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000), n_jobs=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "ovr = OneVsRestClassifier(lr, n_jobs=-1)\n",
    "ovr.fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e61240b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = ovr.predict(train_texts)\n",
    "y_val_preds = ovr.predict(val_texts)\n",
    "y_test_preds = ovr.predict(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b54b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: macro - f1_score: 0.6287088605331834\n",
      "train: micro - f1_score: 0.7671352088592136\n",
      "train: macro - recall: 0.5602337917932163\n",
      "train: micro - recall: 0.7238506381875283\n",
      "train: macro - precision: 0.801878231662428\n",
      "train: micro - precision: 0.8159256492698083\n",
      "val: macro - f1_score: 0.44314485144175575\n",
      "val: micro - f1_score: 0.7366167462252361\n",
      "val: macro - recall: 0.3969946274670088\n",
      "val: micro - recall: 0.6947557582315659\n",
      "val: macro - precision: 0.5434305381501641\n",
      "val: micro - precision: 0.7838456507521255\n",
      "test: macro - f1_score: 0.44670151530110175\n",
      "test: micro - f1_score: 0.7346048867650795\n",
      "test: macro - recall: 0.40026358761421077\n",
      "test: micro - recall: 0.6955468980396418\n",
      "test: macro - precision: 0.5422019101236327\n",
      "test: micro - precision: 0.7783104071140753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/articleclassifier/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "for dataset_name, (dataset_pred, dataset_real) in {'train': (y_train_preds, train_labels), 'val': (y_val_preds, val_labels), 'test': (y_test_preds, test_labels)}.items():\n",
    "    for metric_name, metric in {'f1_score': f1_score, 'recall': recall_score, 'precision': precision_score}.items():\n",
    "        for averaging_type in ['macro', 'micro']:\n",
    "            print(f'{dataset_name}: {averaging_type} - {metric_name}: {metric(dataset_real, dataset_pred, average=averaging_type)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dadc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-articleclassifier [Python]",
   "language": "python",
   "name": "conda-env-.conda-articleclassifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
