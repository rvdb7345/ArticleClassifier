{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Employing GNNs for multi-label classification of biomedical articles Welcome to the documentation of this project. The documentation will cover the different aspects of the project, namely: * Setting up the project * Creating the right settings * Preparing the data * Training a model * Optimising a model General Remarks This project was created as a 3-month Master Thesis project for the program Information Studies - Data Science. The project was done at Elsevier under the supervision of Bruno Martins and Chieling Yueh.","title":"Index"},{"location":"#employing-gnns-for-multi-label-classification-of-biomedical-articles","text":"Welcome to the documentation of this project. The documentation will cover the different aspects of the project, namely: * Setting up the project * Creating the right settings * Preparing the data * Training a model * Optimising a model","title":"Employing GNNs for multi-label classification of biomedical articles"},{"location":"#general-remarks","text":"This project was created as a 3-month Master Thesis project for the program Information Studies - Data Science. The project was done at Elsevier under the supervision of Bruno Martins and Chieling Yueh.","title":"General Remarks"},{"location":"optimization/","text":"Optimising a model As each model comprises of separate components, we optimise each component individually. The components in question are: * GNN * Classification head","title":"Optimization"},{"location":"optimization/#optimising-a-model","text":"As each model comprises of separate components, we optimise each component individually. The components in question are: * GNN * Classification head","title":"Optimising a model"},{"location":"preparing_data/","text":"Preparing data This ReadMe explains how to prepare your data sources from the raw CARs to finetuned embedding text and graph networks. Processing CAR data ^^^^^^^^^^^^^^^^^^^ From the CAR data we create a single CSV file to work with, extracting the data that we want. Creating graph networks ^^^^^^^^^^^^^^^^^^^^^^^ To train GNNs, we need graph networks. We build them using the create_author_networks.py and create_keyword_networks.py files. make sure the environment is built from the requirements.txt file. build the datasets as described in the data_preparation folder Training a model ^^^^^^^^^^^^^^^^","title":"Data Preparation"},{"location":"preparing_data/#preparing-data","text":"This ReadMe explains how to prepare your data sources from the raw CARs to finetuned embedding text and graph networks. Processing CAR data ^^^^^^^^^^^^^^^^^^^ From the CAR data we create a single CSV file to work with, extracting the data that we want. Creating graph networks ^^^^^^^^^^^^^^^^^^^^^^^ To train GNNs, we need graph networks. We build them using the create_author_networks.py and create_keyword_networks.py files. make sure the environment is built from the requirements.txt file. build the datasets as described in the data_preparation folder Training a model ^^^^^^^^^^^^^^^^","title":"Preparing data"},{"location":"project_installation/","text":"Project Installation","title":"Setting up"},{"location":"project_installation/#project-installation","text":"","title":"Project Installation"},{"location":"settings/","text":"Configuring the right settings","title":"Configuring Settings"},{"location":"settings/#configuring-the-right-settings","text":"","title":"Configuring the right settings"},{"location":"training/","text":"Training This ReadMe explains how to train and evaluate a GNN on the data using the command line and the steps that are required to get get there. Before training a model ^^^^^^^^^^^^^^^^^^^^^^^ make sure the environment is built from the requirements.txt file. build the datasets as described in the data_preparation folder Training a model ^^^^^^^^^^^^^^^^","title":"Training"},{"location":"training/#training","text":"This ReadMe explains how to train and evaluate a GNN on the data using the command line and the steps that are required to get get there. Before training a model ^^^^^^^^^^^^^^^^^^^^^^^ make sure the environment is built from the requirements.txt file. build the datasets as described in the data_preparation folder Training a model ^^^^^^^^^^^^^^^^","title":"Training"},{"location":"welcome/","text":"Welcome to the GNN article classification repo! Testing the docs here. Viewing the documentation mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Welcome to the GNN article classification repo!"},{"location":"welcome/#welcome-to-the-gnn-article-classification-repo","text":"Testing the docs here.","title":"Welcome to the GNN article classification repo!"},{"location":"welcome/#viewing-the-documentation","text":"mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Viewing the documentation"}]}