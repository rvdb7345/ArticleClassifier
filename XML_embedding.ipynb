{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8180e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vocab building: : 456009it [00:23, 19505.22it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import timeit\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import src.general.global_variables as gv\n",
    "from src.general.utils import cc_path\n",
    "\n",
    "sys.path.append(gv.PROJECT_PATH)\n",
    "\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname('data_loader.py'), os.path.pardir)))\n",
    "from src.data.data_loader import DataLoader\n",
    "\n",
    "# def load_data(data_path, max_length, vocab_size, batch_size=64):\n",
    "#     X_trn, Y_trn, X_tst, Y_tst, vocabulary, vocabulary_inv = data_helpers.load_data(data_path, max_length=max_length,\n",
    "#                                                                                     vocab_size=vocab_size)\n",
    "#     Y_trn = Y_trn[0:].toarray()\n",
    "#     Y_trn = np.insert(Y_trn, 101, 0, axis=1)\n",
    "#     Y_trn = np.insert(Y_trn, 102, 0, axis=1)\n",
    "#     Y_tst = Y_tst[0:].toarray()\n",
    "#\n",
    "#     train_data = data_utils.TensorDataset(torch.from_numpy(X_trn).type(torch.LongTensor),\n",
    "#                                           torch.from_numpy(Y_trn).type(torch.LongTensor))\n",
    "#     test_data = data_utils.TensorDataset(torch.from_numpy(X_tst).type(torch.LongTensor),\n",
    "#                                          torch.from_numpy(Y_tst).type(torch.LongTensor))\n",
    "#     train_loader = data_utils.DataLoader(train_data, batch_size, drop_last=False, shuffle=True)\n",
    "#     test_loader = data_utils.DataLoader(test_data, batch_size, drop_last=False)\n",
    "#     return train_loader, test_loader, vocabulary, X_tst, Y_tst, X_trn, Y_trn\n",
    "\n",
    "def precision_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    precision = []\n",
    "    for _k in k:\n",
    "        p = 0\n",
    "        for i in range(batch_size):\n",
    "            p += label[i, pred[i, :_k]].mean()\n",
    "        precision.append(p * 100 / batch_size)\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def ndcg_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    ndcg = []\n",
    "    for _k in k:\n",
    "        score = 0\n",
    "        rank = np.log2(np.arange(2, 2 + _k))\n",
    "        for i in range(batch_size):\n",
    "            l = label[i, pred[i, :_k]]\n",
    "            n = l.sum()\n",
    "            if (n == 0):\n",
    "                continue\n",
    "\n",
    "            dcg = (l / rank).sum()\n",
    "            label_count = label[i].sum()\n",
    "            norm = 1 / np.log2(np.arange(2, 2 + np.min((_k, label_count))))\n",
    "            norm = norm.sum()\n",
    "            score += dcg / norm\n",
    "\n",
    "        ndcg.append(score * 100 / batch_size)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "\n",
    "# input data_path\n",
    "# data_path = '/data/rcv1_raw_text.p'\n",
    "sequence_length = 500\n",
    "batch_size = 64\n",
    "\n",
    "def load_glove_embeddings(path, embedding_dim):\n",
    "    \"\"\"Loading the glove embeddings\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        embeddings = np.zeros((len(lines)+1, embedding_dim))\n",
    "        word_idx_dict = {}\n",
    "        for index, line in tqdm(enumerate(lines), desc='vocab building: '):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word_idx_dict[word] = index + 1\n",
    "            if index:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                if vector.shape[-1] != embedding_dim:\n",
    "                    raise Exception('Dimension not matching.')\n",
    "                embeddings[index] = vector\n",
    "\n",
    "    return torch.from_numpy(embeddings).float(), word_idx_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load glove\n",
    "pretrain = 'glove'\n",
    "embedding_dim = 128\n",
    "# input word2vec file path\n",
    "file_path = cc_path(f'data/processed/canary/word_embeddings_{pretrain}.txt')\n",
    "embedding_weights, word_idx_dict = load_glove_embeddings(file_path, embedding_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81676e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chi19mk': 1,\n",
       " 'rs7839488': 2,\n",
       " 'manufactories': 3,\n",
       " 'li0': 4,\n",
       " 'httpsclinicaltrialsgovct2shownct03924414': 5,\n",
       " 'n396': 6,\n",
       " 'nodiflora': 7,\n",
       " 'sequestration': 8,\n",
       " '3qter': 9,\n",
       " 'bov': 10,\n",
       " 'tetracyclineresponsive': 11,\n",
       " 'mthfd2': 12,\n",
       " 'borylative': 13,\n",
       " '8477': 14,\n",
       " 'ssrt3': 15,\n",
       " 'interleukin12': 16,\n",
       " 'peti': 17,\n",
       " 't1273se': 18,\n",
       " 'literal': 19,\n",
       " 'ibfds': 20,\n",
       " 'glutmtx': 21,\n",
       " '56178': 22,\n",
       " 'm0mφs': 23,\n",
       " 'rotationflipping': 24,\n",
       " '10061014': 25,\n",
       " 'enthesitisrelated': 26,\n",
       " 'caftaric': 27,\n",
       " '10700': 28,\n",
       " 'pseudopods': 29,\n",
       " 'grown': 30,\n",
       " 'cox5b': 31,\n",
       " 'thirdmolar': 32,\n",
       " 'vcfeval': 33,\n",
       " '34secolupane': 34,\n",
       " 'microrna148a3p': 35,\n",
       " 'productionchondroitin': 36,\n",
       " 'wrightcoombs': 37,\n",
       " 'estiage': 38,\n",
       " 'hksar': 39,\n",
       " '8027': 40,\n",
       " 'pomderived': 41,\n",
       " 'attainment': 42,\n",
       " '6induced': 43,\n",
       " 'solutionbased': 44,\n",
       " 'alinduced': 45,\n",
       " '103108': 46,\n",
       " 'mobileevent': 47,\n",
       " '07287': 48,\n",
       " 'prokka': 49,\n",
       " '09600993': 50,\n",
       " '118442': 51,\n",
       " 'cerrobend': 52,\n",
       " 'lrrk2nmc': 53,\n",
       " 'alfalfaleucaena': 54,\n",
       " '4421733': 55,\n",
       " 'hn001': 56,\n",
       " 'swept': 57,\n",
       " 'devane': 58,\n",
       " '09341089': 59,\n",
       " 'rushing': 60,\n",
       " 'haemoplasmas': 61,\n",
       " 'atbbe15': 62,\n",
       " 'u2af1': 63,\n",
       " 'secondarytertiarylevel': 64,\n",
       " 'baxdeficiency': 65,\n",
       " 'diffusemultiple': 66,\n",
       " 'ss0027': 67,\n",
       " 'wmscofe2o4': 68,\n",
       " 'ptal2o3': 69,\n",
       " 'emss': 70,\n",
       " 'fistulising': 71,\n",
       " 'mortalitymistroke': 72,\n",
       " 'naso': 73,\n",
       " 'atazanavir': 74,\n",
       " 'protamine': 75,\n",
       " '9532': 76,\n",
       " 'exorbitant': 77,\n",
       " '106390': 78,\n",
       " 'ca90': 79,\n",
       " '30395': 80,\n",
       " '3921132': 81,\n",
       " '2heptyl3hydroxyquinolin41hone': 82,\n",
       " 'psdassociated': 83,\n",
       " 'equatorial': 84,\n",
       " 'uvcinduced': 85,\n",
       " 'spirometricallydefined': 86,\n",
       " 'prediabetesaware': 87,\n",
       " 'covidward': 88,\n",
       " 'sflt': 89,\n",
       " 'spopbinding': 90,\n",
       " 'cancerhiv': 91,\n",
       " 'la13': 92,\n",
       " '4hydroxy3methoxy': 93,\n",
       " 'midcretaceousinclude': 94,\n",
       " 'il13il13rα2mediated': 95,\n",
       " 'pretest154703968': 96,\n",
       " 'efv400based': 97,\n",
       " 'spliceseq': 98,\n",
       " '58296': 99,\n",
       " 'bacteriophage': 100,\n",
       " 'mgat4a': 101,\n",
       " 'kriaučeliūnas': 102,\n",
       " 'woredas': 103,\n",
       " 'singleround': 104,\n",
       " '30cm': 105,\n",
       " 'vrcz': 106,\n",
       " 'cardiovascularunexplained': 107,\n",
       " 'balancereaction': 108,\n",
       " 'σtu': 109,\n",
       " 'alkylphosphocholine': 110,\n",
       " 'fpf': 111,\n",
       " 'mymemcheck': 112,\n",
       " 'blvii28': 113,\n",
       " 'nct02926417': 114,\n",
       " 'hadmsctreated': 115,\n",
       " 'nocardamine': 116,\n",
       " 'caf': 117,\n",
       " 'hexag6': 118,\n",
       " 'nonemployment': 119,\n",
       " 'album': 120,\n",
       " 'n77': 121,\n",
       " 'rul': 122,\n",
       " 'initialisation': 123,\n",
       " 'syntax': 124,\n",
       " 'newestgeneration': 125,\n",
       " 'mucoides': 126,\n",
       " '1939t': 127,\n",
       " 'feoh2': 128,\n",
       " 'easyhaler': 129,\n",
       " '346937': 130,\n",
       " 'repbase': 131,\n",
       " 'uvm7': 132,\n",
       " 'isolatezy462471from': 133,\n",
       " 'sparged': 134,\n",
       " 'parities': 135,\n",
       " 'cox': 136,\n",
       " 'ci9581237': 137,\n",
       " 'nonmmc': 138,\n",
       " 'patternacute': 139,\n",
       " '50150': 140,\n",
       " 'nonfluoroquinolone': 141,\n",
       " 'fescue': 142,\n",
       " 'relapsingonset': 143,\n",
       " 'elk3icam1': 144,\n",
       " 'forprofitcompany': 145,\n",
       " 'methanebased': 146,\n",
       " 'negativelyregulated': 147,\n",
       " 'mstrg128958': 148,\n",
       " 'rsie': 149,\n",
       " '345dimethylthylthiazol2yl25': 150,\n",
       " 't233': 151,\n",
       " 'nccderivatives': 152,\n",
       " '2hydroxy4oxo4thien2ylbut2enoates': 153,\n",
       " 'degenerated': 154,\n",
       " 'bt18t': 155,\n",
       " 'doer': 156,\n",
       " 'ketosidic': 157,\n",
       " 'supposed': 158,\n",
       " 'so2': 159,\n",
       " 'k127': 160,\n",
       " '08438': 161,\n",
       " 'gcdmm': 162,\n",
       " 'sorl1': 163,\n",
       " 'aborally': 164,\n",
       " '3224': 165,\n",
       " '9913': 166,\n",
       " '12pss': 167,\n",
       " 'csds': 168,\n",
       " 'infectionsnewer': 169,\n",
       " 'garcinia': 170,\n",
       " 'vs76471': 171,\n",
       " 'pellucidi': 172,\n",
       " 'isoor': 173,\n",
       " 'piezotolerans': 174,\n",
       " 'bronchialabdominal': 175,\n",
       " 'lindi': 176,\n",
       " 'tap2': 177,\n",
       " 'irritationfree': 178,\n",
       " 'aqueousethanolic': 179,\n",
       " 'en1positive': 180,\n",
       " '9691': 181,\n",
       " 'snapping': 182,\n",
       " 'enquired': 183,\n",
       " 'melanurus': 184,\n",
       " 'hypometriosis': 185,\n",
       " 'onelegged': 186,\n",
       " '35yearsold': 187,\n",
       " 'payerbased': 188,\n",
       " '2s3r6s': 189,\n",
       " 'sjet': 190,\n",
       " 'mric1': 191,\n",
       " '10kilogram': 192,\n",
       " 'sevasharam': 193,\n",
       " 'febric': 194,\n",
       " 'p4pgr': 195,\n",
       " '5781090': 196,\n",
       " 'pcornet': 197,\n",
       " '87years': 198,\n",
       " 'axialplane': 199,\n",
       " 'derivable': 200,\n",
       " 'regulatorysmads': 201,\n",
       " 'cotransfection': 202,\n",
       " 'casereviews': 203,\n",
       " '17dmag': 204,\n",
       " '1078': 205,\n",
       " 'morphometric': 206,\n",
       " '265436': 207,\n",
       " 'padonly': 208,\n",
       " 'bvdv1b': 209,\n",
       " 'updi': 210,\n",
       " 'uio68tzdc': 211,\n",
       " 'telnoaa': 212,\n",
       " '24565': 213,\n",
       " '27bp': 214,\n",
       " 'piratiningaitaipu': 215,\n",
       " 'hpmctriacetin': 216,\n",
       " 'bher2negative': 217,\n",
       " 'kikwit': 218,\n",
       " 'ror044': 219,\n",
       " 'rtecs': 220,\n",
       " 'igg2δa': 221,\n",
       " 'cacdr2p': 222,\n",
       " 'sup18supffluorodeoxyglucose': 223,\n",
       " 'selfdefence': 224,\n",
       " 'gluzincin': 225,\n",
       " 'brainv25gy': 226,\n",
       " 'nipplesparing': 227,\n",
       " 'catchment': 228,\n",
       " 'gcsfproducing': 229,\n",
       " '7656': 230,\n",
       " 'housefly': 231,\n",
       " 'cckrelated': 232,\n",
       " 'selflogin': 233,\n",
       " 'toxicpred': 234,\n",
       " 'firth': 235,\n",
       " 'il1r1l': 236,\n",
       " 'hze': 237,\n",
       " 'pmi': 238,\n",
       " 'virucide': 239,\n",
       " 'scoretwice': 240,\n",
       " 'wilayas': 241,\n",
       " 'ilma': 242,\n",
       " '164026738': 243,\n",
       " 'phylathe': 244,\n",
       " 'trp358': 245,\n",
       " '955396': 246,\n",
       " 'cllnoncll': 247,\n",
       " '61140': 248,\n",
       " 'ccpp': 249,\n",
       " 'ormepolizumab': 250,\n",
       " 'clamart': 251,\n",
       " '273787': 252,\n",
       " 'ctri201805014176': 253,\n",
       " '201719': 254,\n",
       " 'conjectural': 255,\n",
       " 'nonindigenous': 256,\n",
       " 'teens': 257,\n",
       " '151cases': 258,\n",
       " 'virginolive': 259,\n",
       " 'minilaparoscopic': 260,\n",
       " 'lagniappes': 261,\n",
       " 'lcqqqmsms': 262,\n",
       " 'crlf2': 263,\n",
       " 'nucleated': 264,\n",
       " 'koreawide': 265,\n",
       " '2224yearold': 266,\n",
       " 'suborder': 267,\n",
       " 'preexistingpregestational': 268,\n",
       " 'mirnastargeted': 269,\n",
       " 'mysugr': 270,\n",
       " 'darui': 271,\n",
       " 'antiscarring': 272,\n",
       " 'p0296': 273,\n",
       " '066102': 274,\n",
       " 'parietalia': 275,\n",
       " '064078': 276,\n",
       " '11749': 277,\n",
       " 'poly2methacryloyloxyethyl': 278,\n",
       " 'forcing': 279,\n",
       " 'iodinei2': 280,\n",
       " 'cd32b': 281,\n",
       " 'matchingpsm': 282,\n",
       " 'mir650': 283,\n",
       " 'carbonnmr': 284,\n",
       " 'hypervalent': 285,\n",
       " '268112500': 286,\n",
       " 'agde': 287,\n",
       " 'sudipg6': 288,\n",
       " 'lipf6pp': 289,\n",
       " 'survivaldeath': 290,\n",
       " 'audiences': 291,\n",
       " '324390': 292,\n",
       " 'αsantalol': 293,\n",
       " 'psma2shrna': 294,\n",
       " 'hemihypertrophy': 295,\n",
       " 'champions': 296,\n",
       " 'sscbs': 297,\n",
       " 'premirs15a5p': 298,\n",
       " 'eb1': 299,\n",
       " '3395': 300,\n",
       " 'lcesimsms': 301,\n",
       " 'soilwaste': 302,\n",
       " 'alcoholammonium': 303,\n",
       " 'avoidant': 304,\n",
       " 'atterm': 305,\n",
       " 'cerner': 306,\n",
       " 'pdagceo2': 307,\n",
       " 'humanoriginated': 308,\n",
       " 'tincrmediated': 309,\n",
       " 'fecg': 310,\n",
       " 'comeback': 311,\n",
       " 'imkr': 312,\n",
       " 'computed': 313,\n",
       " 'okamotoi': 314,\n",
       " 'perubatan': 315,\n",
       " '320507': 316,\n",
       " 'hichip': 317,\n",
       " 'nh₄₂so₄': 318,\n",
       " 'botanicals': 319,\n",
       " 'jours': 320,\n",
       " '0664': 321,\n",
       " 'réductions': 322,\n",
       " 'leftbundlebranch': 323,\n",
       " 'family': 324,\n",
       " 'goldfishlike': 325,\n",
       " 'cssparing': 326,\n",
       " 'aaz': 327,\n",
       " 'atpasehelicasenull': 328,\n",
       " 'ap5cnqx': 329,\n",
       " 'p0990': 330,\n",
       " 'ci3653': 331,\n",
       " 'rad5p24': 332,\n",
       " 'nisgen': 333,\n",
       " 'heatsensing': 334,\n",
       " '2990': 335,\n",
       " 'lsmr32': 336,\n",
       " '108238': 337,\n",
       " 'jaszczak': 338,\n",
       " '64year': 339,\n",
       " 'majora': 340,\n",
       " 'mentalactual': 341,\n",
       " 'nonadministration': 342,\n",
       " '57016135726': 343,\n",
       " '11053': 344,\n",
       " 'thermogenically': 345,\n",
       " '1891056': 346,\n",
       " 'birdsgroup': 347,\n",
       " 'noncvvh': 348,\n",
       " 'amendmentsconditioners': 349,\n",
       " 'δentropy': 350,\n",
       " '1157nucleotide': 351,\n",
       " 'ranged': 352,\n",
       " '23100': 353,\n",
       " 'stentfenestrated': 354,\n",
       " 'cmnc': 355,\n",
       " 'gravely': 356,\n",
       " 'phomopsisin': 357,\n",
       " '116232': 358,\n",
       " 'perkinduced': 359,\n",
       " 'interspecies': 360,\n",
       " 'caarms': 361,\n",
       " 'physiologicallystructured': 362,\n",
       " 'urinalysis': 363,\n",
       " '995910705': 364,\n",
       " 'mesuaferrone': 365,\n",
       " 'persistentprogressive': 366,\n",
       " 'effectortotarget': 367,\n",
       " 'smearnegative': 368,\n",
       " 'opticfield': 369,\n",
       " 'antivirals': 370,\n",
       " 'bred': 371,\n",
       " 'phe325': 372,\n",
       " 'confinementrelated': 373,\n",
       " 'bipinnatum': 374,\n",
       " '021111': 375,\n",
       " 'reos': 376,\n",
       " 'wdr43': 377,\n",
       " 'malerelated': 378,\n",
       " 'industrialization': 379,\n",
       " 'dotlike': 380,\n",
       " 'nisrna': 381,\n",
       " '110129': 382,\n",
       " '649884': 383,\n",
       " 'adaptivear': 384,\n",
       " 'crossing': 385,\n",
       " 'l683': 386,\n",
       " 'piama': 387,\n",
       " 'c1946ct': 388,\n",
       " 'acaeg': 389,\n",
       " 'holography': 390,\n",
       " 'insecticideexposed': 391,\n",
       " 'gambusia': 392,\n",
       " 'lipodysfunction': 393,\n",
       " 'cr88': 394,\n",
       " 'm95i': 395,\n",
       " 'il1βtreatedhtdcs': 396,\n",
       " 'o9': 397,\n",
       " 'ildk': 398,\n",
       " 'enhancertkluciferase': 399,\n",
       " 'megalocytiviruses': 400,\n",
       " '150permanent': 401,\n",
       " 'oxygencentered': 402,\n",
       " 'nonmagnifying': 403,\n",
       " '91335': 404,\n",
       " 'anisochilus': 405,\n",
       " 'eccentricitymatched': 406,\n",
       " 'incontinenceformula': 407,\n",
       " 'th1promoting': 408,\n",
       " 'dibromoacetic': 409,\n",
       " 'evil': 410,\n",
       " 'biorepository': 411,\n",
       " 'exposedfibroblasts': 412,\n",
       " 'pgm2': 413,\n",
       " '330bed': 414,\n",
       " 'diazotrophs': 415,\n",
       " 'cmapmethods': 416,\n",
       " '11743910': 417,\n",
       " 'coriandrum': 418,\n",
       " 'boyfriendgirlfriend': 419,\n",
       " 'cemeteries': 420,\n",
       " 'bod5cod': 421,\n",
       " 'bph': 422,\n",
       " '045|r|063': 423,\n",
       " 'caffeys': 424,\n",
       " 'a375s2': 425,\n",
       " 'osns': 426,\n",
       " '6fpc': 427,\n",
       " 'shocks': 428,\n",
       " 'arguably': 429,\n",
       " 'lightdriven': 430,\n",
       " 'cefalee': 431,\n",
       " '7606': 432,\n",
       " 'nouveau': 433,\n",
       " '34084': 434,\n",
       " '148iui': 435,\n",
       " 'paramagneticism': 436,\n",
       " 'shedded': 437,\n",
       " 'methocarbamol': 438,\n",
       " 'parametersbmi': 439,\n",
       " 'handgrips': 440,\n",
       " 'optovue': 441,\n",
       " '12625': 442,\n",
       " 'grail': 443,\n",
       " 'ydcc': 444,\n",
       " '1508100': 445,\n",
       " '321326': 446,\n",
       " '51863': 447,\n",
       " 'µggcell': 448,\n",
       " 'secsaxs': 449,\n",
       " 'ramachandran': 450,\n",
       " 'nonactive': 451,\n",
       " 'cfz': 452,\n",
       " 'nct00903110': 453,\n",
       " 'cindex0649': 454,\n",
       " '2503075': 455,\n",
       " 'znopvdftrfe': 456,\n",
       " 'determinedthe': 457,\n",
       " 'homocysteinemia': 458,\n",
       " '17340tnbrc': 459,\n",
       " '10hztacs': 460,\n",
       " 'megakaryocytesplatelets': 461,\n",
       " 'influençant': 462,\n",
       " 'semipre': 463,\n",
       " 'clinimetric': 464,\n",
       " 'jak1stat1irf1': 465,\n",
       " '240261': 466,\n",
       " 'ifit2depleted': 467,\n",
       " 'mccormack': 468,\n",
       " 'cdo': 469,\n",
       " '02610487': 470,\n",
       " 'aor13': 471,\n",
       " '3259864': 472,\n",
       " 'trimmed': 473,\n",
       " 'nonctbased': 474,\n",
       " 'ethmoid': 475,\n",
       " '8038': 476,\n",
       " '629107': 477,\n",
       " 'tribute': 478,\n",
       " 'crd42018115813': 479,\n",
       " 'yesno': 480,\n",
       " '36919452': 481,\n",
       " 'yesso': 482,\n",
       " 'stb01': 483,\n",
       " 'rm7434': 484,\n",
       " 'losatuxizumab': 485,\n",
       " 'inhalers': 486,\n",
       " 'assuage': 487,\n",
       " '21731956': 488,\n",
       " 'tcvd': 489,\n",
       " 'nontemperature': 490,\n",
       " 'washability': 491,\n",
       " 'increaseno': 492,\n",
       " 'cadcam': 493,\n",
       " '072256': 494,\n",
       " 'tirupati': 495,\n",
       " 'streptozotocinstz': 496,\n",
       " 'ewmh': 497,\n",
       " 'lization': 498,\n",
       " 'undifferentiated': 499,\n",
       " 'alox': 500,\n",
       " 'periquino': 501,\n",
       " 'notch1runx2': 502,\n",
       " 'diarrhetic': 503,\n",
       " 'protectedstreams': 504,\n",
       " 'busters': 505,\n",
       " 'mintlesion': 506,\n",
       " 'pupylation': 507,\n",
       " 'luteinzeaxanthin': 508,\n",
       " 'or03': 509,\n",
       " 'lowtransmission': 510,\n",
       " 'prefield': 511,\n",
       " 'serratia': 512,\n",
       " 'lpa5': 513,\n",
       " 'albertlasker': 514,\n",
       " 'stryde': 515,\n",
       " 'ejector': 516,\n",
       " 'isomap': 517,\n",
       " 'nhdlchdlc': 518,\n",
       " 'cellhemoglobin': 519,\n",
       " '128399': 520,\n",
       " 'vb23tdsm': 521,\n",
       " 'isac': 522,\n",
       " 'racepolymerase': 523,\n",
       " 'southsouthwest': 524,\n",
       " 'αsecretase': 525,\n",
       " 'foveadisc': 526,\n",
       " 'solider': 527,\n",
       " 'h2bub': 528,\n",
       " 't4bn2cm0': 529,\n",
       " 'imatinib40': 530,\n",
       " '16330': 531,\n",
       " 'g196a': 532,\n",
       " 'vctp': 533,\n",
       " 'checks': 534,\n",
       " 'vriddhi': 535,\n",
       " 'lmo0098': 536,\n",
       " 'neuralimmuneassociated': 537,\n",
       " 'malonidialdehyde': 538,\n",
       " 'brandnew': 539,\n",
       " 'anrspediacam': 540,\n",
       " 'nitrosubstituted': 541,\n",
       " 'cu3tabto2mof': 542,\n",
       " 'aqp2': 543,\n",
       " 'alkalitolerant': 544,\n",
       " 'seropositives': 545,\n",
       " '188826': 546,\n",
       " '21216': 547,\n",
       " 'bump': 548,\n",
       " 'postgrafting': 549,\n",
       " 'fev1fev3': 550,\n",
       " 'jcpyv': 551,\n",
       " 'tnfsf15dr3': 552,\n",
       " 'industryregulators': 553,\n",
       " 'fchange': 554,\n",
       " 'ω1methoxy': 555,\n",
       " 'febrile': 556,\n",
       " 'srcr56': 557,\n",
       " 'neoadjuvant': 558,\n",
       " '501072': 559,\n",
       " 'derogatory': 560,\n",
       " 'leachable': 561,\n",
       " 'retroreflective': 562,\n",
       " 'afterripened': 563,\n",
       " 'resonates': 564,\n",
       " 'dementiapartly': 565,\n",
       " 'pharmacistinitiated': 566,\n",
       " 'spinelevel': 567,\n",
       " 'cationradical': 568,\n",
       " '2hydroxypropylbetacyclodextrin': 569,\n",
       " 'averagescattererdiameter': 570,\n",
       " 'turkstat': 571,\n",
       " 'npdb': 572,\n",
       " 'riib': 573,\n",
       " 'wholecounty': 574,\n",
       " 'irds': 575,\n",
       " 'x20421': 576,\n",
       " 'compounddependent': 577,\n",
       " 'aeruginosathe': 578,\n",
       " '5084': 579,\n",
       " 'wpossess': 580,\n",
       " 'eightway': 581,\n",
       " 'srcap': 582,\n",
       " 'wgrwgrnw': 583,\n",
       " 'm1pax': 584,\n",
       " 'icfree': 585,\n",
       " 'cd4tcd8t': 586,\n",
       " '850950': 587,\n",
       " 'nonsensory': 588,\n",
       " '393460': 589,\n",
       " 'assimilationbatch': 590,\n",
       " 'aidoaaa1600019': 591,\n",
       " 'schenckii': 592,\n",
       " '119334': 593,\n",
       " '116251': 594,\n",
       " 'terrificus': 595,\n",
       " 'scenario': 596,\n",
       " 'gdl45': 597,\n",
       " '101672': 598,\n",
       " '109520': 599,\n",
       " 'tfus': 600,\n",
       " 'considérer': 601,\n",
       " '303444': 602,\n",
       " 'beatbased': 603,\n",
       " 'bilecolored': 604,\n",
       " 'nagi': 605,\n",
       " 'sonazoidenhanced': 606,\n",
       " '42504': 607,\n",
       " '13864': 608,\n",
       " 'salinitydependent': 609,\n",
       " 'ssro': 610,\n",
       " 'epiphytic': 611,\n",
       " 'unreached': 612,\n",
       " '039094': 613,\n",
       " 'tcells': 614,\n",
       " '809fold': 615,\n",
       " 'thermotolerance': 616,\n",
       " 'porphyrin': 617,\n",
       " 'ghanas': 618,\n",
       " 'fde4a': 619,\n",
       " 'lighth2o2': 620,\n",
       " 'epitopebased': 621,\n",
       " 'nchek293': 622,\n",
       " 'anticorrelated': 623,\n",
       " 'prlt': 624,\n",
       " 'oabcare': 625,\n",
       " 'phthisical': 626,\n",
       " 'clascorterone': 627,\n",
       " 'fsbmfed': 628,\n",
       " '14dayold': 629,\n",
       " 'kfe8tat125': 630,\n",
       " 'frrrelated': 631,\n",
       " 'yg7': 632,\n",
       " '90113': 633,\n",
       " 'hcoo': 634,\n",
       " 'gse47797': 635,\n",
       " '296g': 636,\n",
       " 'galpglk': 637,\n",
       " 'cbctpop': 638,\n",
       " 'heterotaxies': 639,\n",
       " 'mir378': 640,\n",
       " '8124': 641,\n",
       " '3ethyl3hydroxy5alphaandrostan17one': 642,\n",
       " 'colquitt': 643,\n",
       " 'p000386': 644,\n",
       " 'lymphocytve': 645,\n",
       " '10466757': 646,\n",
       " 'mir4975pccne1': 647,\n",
       " '956': 648,\n",
       " '53418': 649,\n",
       " '7237': 650,\n",
       " 'pulsedphase': 651,\n",
       " 'cghp': 652,\n",
       " 'aspiration': 653,\n",
       " 'study': 654,\n",
       " 'adars': 655,\n",
       " 'typeblood': 656,\n",
       " 'bronchoalveolarfluid': 657,\n",
       " 'p00189': 658,\n",
       " 'nonperimesencephalic': 659,\n",
       " 'unirrigated': 660,\n",
       " 'lympocyte': 661,\n",
       " 'ubcas': 662,\n",
       " 'danfodiyo': 663,\n",
       " 'mmi1': 664,\n",
       " 'sation': 665,\n",
       " 'heterophyidparticularly': 666,\n",
       " '456bp': 667,\n",
       " '081366': 668,\n",
       " 'fusional': 669,\n",
       " 'pruning': 670,\n",
       " 'intronexon': 671,\n",
       " 'odontogenesis': 672,\n",
       " 'auyear': 673,\n",
       " 'ubiquis': 674,\n",
       " 'occipitomastoid': 675,\n",
       " 'ps001': 676,\n",
       " 'spif': 677,\n",
       " 'weusten': 678,\n",
       " 'linc01524': 679,\n",
       " 'porcellus': 680,\n",
       " 'asaq': 681,\n",
       " '37215': 682,\n",
       " '000043': 683,\n",
       " 'semimetal': 684,\n",
       " 'postje': 685,\n",
       " 'pawi2': 686,\n",
       " 'highblood': 687,\n",
       " 'alloderm': 688,\n",
       " 'postrp': 689,\n",
       " 'broilers': 690,\n",
       " 'pradesh': 691,\n",
       " 'sroc': 692,\n",
       " 'speleocoopi': 693,\n",
       " 'copingwithstress': 694,\n",
       " '87466': 695,\n",
       " 'algorithmarticulated': 696,\n",
       " 'sensorfasor': 697,\n",
       " 'pltem': 698,\n",
       " 'honokiolmagnolollecithinnadoc': 699,\n",
       " 'smallparticle': 700,\n",
       " 'tnfαtriggered': 701,\n",
       " '2og': 702,\n",
       " 'childturcottepugh': 703,\n",
       " 'panbet': 704,\n",
       " '84373': 705,\n",
       " 'nhsqw': 706,\n",
       " 'cu2ions': 707,\n",
       " 'offal': 708,\n",
       " '2fl': 709,\n",
       " 'steroidimmunosuppressant': 710,\n",
       " 'ci108129': 711,\n",
       " 'generation': 712,\n",
       " 'aerobicanaerobic': 713,\n",
       " 'gemrefractory': 714,\n",
       " '13331621': 715,\n",
       " '045133': 716,\n",
       " 'propargylation': 717,\n",
       " 'valida': 718,\n",
       " '9694': 719,\n",
       " '1a1b': 720,\n",
       " '5971': 721,\n",
       " 'p330': 722,\n",
       " 'ci072091': 723,\n",
       " 'amphetamineamp': 724,\n",
       " '1071154': 725,\n",
       " 'galsulfase': 726,\n",
       " '174multiclass': 727,\n",
       " 'körös': 728,\n",
       " 'clinton': 729,\n",
       " 'comfa': 730,\n",
       " '8245': 731,\n",
       " '10701': 732,\n",
       " 'dentacol': 733,\n",
       " 'fmiaffm': 734,\n",
       " '133299': 735,\n",
       " 'mdr1pgp': 736,\n",
       " 'bisab': 737,\n",
       " 'angiomyolipomapure': 738,\n",
       " 'lorkes': 739,\n",
       " 'redbed': 740,\n",
       " 'cvdms': 741,\n",
       " 'oshaped': 742,\n",
       " 'snail': 743,\n",
       " 'nitrergic': 744,\n",
       " 'hoct1f': 745,\n",
       " 'cd52': 746,\n",
       " 'lesionsymptom': 747,\n",
       " '395711': 748,\n",
       " 'cyanomethylated': 749,\n",
       " 'nippv': 750,\n",
       " 'phonomimetic': 751,\n",
       " 'conservedbroken': 752,\n",
       " 'vaccineconfident': 753,\n",
       " 'ankyrin': 754,\n",
       " 'aquaporinbased': 755,\n",
       " 'cleansing': 756,\n",
       " 'intertuberous': 757,\n",
       " '2801819': 758,\n",
       " 'holistically': 759,\n",
       " 'belgrades': 760,\n",
       " '4ply': 761,\n",
       " 'swair': 762,\n",
       " 'motifattenuated': 763,\n",
       " 'egfrmekerk': 764,\n",
       " 'actrn12618000451202': 765,\n",
       " 'cosmetics': 766,\n",
       " 'expb1013': 767,\n",
       " '9428': 768,\n",
       " 'aor215': 769,\n",
       " 'irgarolinduced': 770,\n",
       " 'propofoldexmedetomidine': 771,\n",
       " 'repeatbased': 772,\n",
       " 'gaeq': 773,\n",
       " 'ochreous': 774,\n",
       " 'laspartyl': 775,\n",
       " 'kopanyo': 776,\n",
       " 'slc29a3': 777,\n",
       " 'jpysf': 778,\n",
       " '97years': 779,\n",
       " 'tarsiiformes': 780,\n",
       " '455313': 781,\n",
       " 'ketogenic': 782,\n",
       " 'cyr715': 783,\n",
       " '7771826': 784,\n",
       " 'hladrb114540101': 785,\n",
       " 'gm3targeted': 786,\n",
       " 'rr166': 787,\n",
       " '128348': 788,\n",
       " 'dichotomization': 789,\n",
       " 'bern': 790,\n",
       " '5bdeh': 791,\n",
       " 'positiveionization': 792,\n",
       " 'pentakis': 793,\n",
       " '2892': 794,\n",
       " 'pcdnanc': 795,\n",
       " 'suggestiveconfirmatory': 796,\n",
       " 'effificiency': 797,\n",
       " '2014june': 798,\n",
       " 'pc12p1d10': 799,\n",
       " 'naturally': 800,\n",
       " 'flowmediateddilatation': 801,\n",
       " 'basetobase': 802,\n",
       " 'ionizability': 803,\n",
       " 'exoview': 804,\n",
       " 'claveriagimeno': 805,\n",
       " 'mgfa': 806,\n",
       " 'win55212': 807,\n",
       " 'mir1265pproficient': 808,\n",
       " 'simptome': 809,\n",
       " 'jianpiyishen': 810,\n",
       " 'hmg1': 811,\n",
       " 'difference149db': 812,\n",
       " 'pblock': 813,\n",
       " 'retiree': 814,\n",
       " 'subsites': 815,\n",
       " 'normalbirthweight': 816,\n",
       " 'saprotrophs': 817,\n",
       " 'attachment': 818,\n",
       " 'simax': 819,\n",
       " '95154': 820,\n",
       " '7682': 821,\n",
       " 'imagingtesting': 822,\n",
       " 'glycopyrrolateformoterol': 823,\n",
       " 'breeding': 824,\n",
       " 'btamir12481': 825,\n",
       " 'dualporosity': 826,\n",
       " 'pilotplant': 827,\n",
       " 'a53tαsynuclein': 828,\n",
       " 'drivaer': 829,\n",
       " 'dvt': 830,\n",
       " 'albolongus': 831,\n",
       " 'smcp': 832,\n",
       " 'adpprostaglandin': 833,\n",
       " 'lariboisière': 834,\n",
       " 'dodecanoate': 835,\n",
       " 'slitc': 836,\n",
       " 'enchondral': 837,\n",
       " 'dhu': 838,\n",
       " '93863': 839,\n",
       " 'grebes': 840,\n",
       " 'bams': 841,\n",
       " 'rmcorr': 842,\n",
       " 'timeunspecified': 843,\n",
       " 'aop206': 844,\n",
       " 'g3g4': 845,\n",
       " 'zygosaccharomyces': 846,\n",
       " 'lespace': 847,\n",
       " '3700': 848,\n",
       " '13rhydroxydocosahexaenoic': 849,\n",
       " 'multiluminal': 850,\n",
       " '016210': 851,\n",
       " 'nb37': 852,\n",
       " 'fakcontrolled': 853,\n",
       " 'methylradseq': 854,\n",
       " 'cmmbp': 855,\n",
       " 'z124dihydroxyphenyl334dihydroxyphenyl2hydroxyprop2en1one': 856,\n",
       " '000016': 857,\n",
       " 'halb': 858,\n",
       " 'picky': 859,\n",
       " 'databasedescriptive': 860,\n",
       " 'mir101a3p': 861,\n",
       " 'rs1573611': 862,\n",
       " 'ewif': 863,\n",
       " 'sandwichelisa': 864,\n",
       " 'loa11399': 865,\n",
       " '11dichloro22bis4chlorophenylethane': 866,\n",
       " 'has_circ_0041151': 867,\n",
       " '100106': 868,\n",
       " 'evanescently': 869,\n",
       " 'essentiellement': 870,\n",
       " 'i131labelled': 871,\n",
       " 'triplicate': 872,\n",
       " 'postinvasion': 873,\n",
       " 'offtreatmentpatchfree': 874,\n",
       " 'angiiinfused': 875,\n",
       " '04180046': 876,\n",
       " 'quantilebased': 877,\n",
       " '0677409753': 878,\n",
       " 'conv': 879,\n",
       " 'levelss': 880,\n",
       " 'dbil': 881,\n",
       " 'midpalate': 882,\n",
       " 'answere': 883,\n",
       " 'of9': 884,\n",
       " 'hl18': 885,\n",
       " 'cellsmin': 886,\n",
       " '411268': 887,\n",
       " 'hemicholinium3': 888,\n",
       " 'mosaicplasty': 889,\n",
       " '010point': 890,\n",
       " '052063': 891,\n",
       " 'selfparallel': 892,\n",
       " '123357': 893,\n",
       " 'vastatin': 894,\n",
       " 'rick': 895,\n",
       " 'illustrious': 896,\n",
       " 'months5': 897,\n",
       " 'intervalgenetic': 898,\n",
       " 'ctpositron': 899,\n",
       " '6713': 900,\n",
       " 'caryoynencin': 901,\n",
       " 'cd15cd16': 902,\n",
       " 'synaptogenesisrelated': 903,\n",
       " 'quasibiennial': 904,\n",
       " 'coupledplasma': 905,\n",
       " 'fineaerosol': 906,\n",
       " '3rbenzyllaspartate': 907,\n",
       " 'ipvrelated': 908,\n",
       " 'lutris': 909,\n",
       " 'aureusmrsa': 910,\n",
       " 'mglur23': 911,\n",
       " '9002325': 912,\n",
       " 'r225isopropyl2methylcyclohex2enylidene': 913,\n",
       " '4086': 914,\n",
       " 'kerr': 915,\n",
       " 'offcbc': 916,\n",
       " 'oligotrophicus': 917,\n",
       " 'il17secreting': 918,\n",
       " 'myl2': 919,\n",
       " 'lyndra': 920,\n",
       " 'malatya': 921,\n",
       " 'singlerun': 922,\n",
       " 'tumorigenesis': 923,\n",
       " 'sstrpositive': 924,\n",
       " 'deformedwing': 925,\n",
       " '4551': 926,\n",
       " 'audiovestibular': 927,\n",
       " 'siridao': 928,\n",
       " 'vikia': 929,\n",
       " 'necmettin': 930,\n",
       " 'prrsv': 931,\n",
       " 'shapenvl': 932,\n",
       " 'cn0': 933,\n",
       " 'epidydymoorchitis': 934,\n",
       " 'anticaspase3': 935,\n",
       " 'linkagesthe': 936,\n",
       " 'nuptial': 937,\n",
       " 'c12imcl': 938,\n",
       " 'pneumolabyrinth': 939,\n",
       " 'carbamoylated': 940,\n",
       " 'pinel': 941,\n",
       " 'cdpocdiv': 942,\n",
       " 'aroids': 943,\n",
       " 'iso1': 944,\n",
       " '1653': 945,\n",
       " 'ubiquitinindependent': 946,\n",
       " 'synergetic': 947,\n",
       " 'urbanised': 948,\n",
       " 'masticate': 949,\n",
       " 'penetrationaspirationrelated': 950,\n",
       " 'prematurely': 951,\n",
       " 'acidtrigged': 952,\n",
       " 'mobarake': 953,\n",
       " 'wd3': 954,\n",
       " 'δtmtv': 955,\n",
       " 'lavages': 956,\n",
       " 'nanoparticleencapsulated': 957,\n",
       " '4733': 958,\n",
       " 'signalment': 959,\n",
       " 'ccx1hngrax2c': 960,\n",
       " 'chargeinversion': 961,\n",
       " 'antiandrogenic': 962,\n",
       " 'ppls': 963,\n",
       " '10043108': 964,\n",
       " 'p0113': 965,\n",
       " 'wireframe': 966,\n",
       " 'sphnsi': 967,\n",
       " 'zhambyl': 968,\n",
       " 'hsa_circ_0007064': 969,\n",
       " 'mcsst': 970,\n",
       " '966were': 971,\n",
       " 'oejun': 972,\n",
       " 'psattelicited': 973,\n",
       " '56932132r30': 974,\n",
       " 'singleaccess': 975,\n",
       " 'tak721': 976,\n",
       " 'pi3knfκb': 977,\n",
       " 'reversetranscriptionpolymerasechainreaction': 978,\n",
       " 'bioguided': 979,\n",
       " 'inexorable': 980,\n",
       " '479700': 981,\n",
       " '1211669': 982,\n",
       " 'serotoninnoradrenalin': 983,\n",
       " 'gapped': 984,\n",
       " 'icgnanogel': 985,\n",
       " 'harnessing': 986,\n",
       " '6pgds': 987,\n",
       " '860mmol': 988,\n",
       " 'kelmbased': 989,\n",
       " 'trialamericas': 990,\n",
       " 'adaptability': 991,\n",
       " '19752015': 992,\n",
       " 'ania': 993,\n",
       " 'deiminases': 994,\n",
       " 'inoviruses': 995,\n",
       " 'inyr': 996,\n",
       " 'nonmet': 997,\n",
       " 'ci157': 998,\n",
       " 'silicainduced': 999,\n",
       " '953': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94826661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('-' * 50)\n",
    "print('Loading data...');\n",
    "start_time = timeit.default_timer()\n",
    "# load all the data\n",
    "loc_dict = {\n",
    "    'processed_csv': cc_path('data/processed/canary/articles_cleaned.csv'),\n",
    "    'abstract_embeddings': cc_path('data/processed/canary/embeddings_fasttext.csv'),\n",
    "    'keyword_network': cc_path('data/processed/canary/keyword_network.pickle'),\n",
    "    'author_network': cc_path('data/processed/canary/author_network.pickle')\n",
    "}\n",
    "data_loader = DataLoader(loc_dict)\n",
    "processed_df = data_loader.load_processed_csv()\n",
    "\n",
    "embedding_df = data_loader.load_embeddings_csv()\n",
    "embedding_df['pui'] = embedding_df['pui'].astype(str)\n",
    "processed_df['pui'] = processed_df['pui'].astype(str)\n",
    "\n",
    "embedding_df[embedding_df.columns.difference(['pui'])] = \\\n",
    "    (embedding_df[embedding_df.columns.difference(['pui'])] -\n",
    "     embedding_df[embedding_df.columns.difference(['pui'])].mean()) / \\\n",
    "    embedding_df[embedding_df.columns.difference(['pui'])].std()\n",
    "\n",
    "label_columns = processed_df.loc[:, ~processed_df.columns.isin(\n",
    "    ['file_name', 'title', 'keywords', 'abstract', 'abstract_2', 'authors', 'organization', 'chemicals',\n",
    "     'num_refs', 'date-delivered', 'labels_m', 'labels_a', 'Unnamed 0:'])]\n",
    "\n",
    "label_columns = label_columns[label_columns.pui.isin(embedding_df.pui)].reset_index(drop=True)\n",
    "abstracts_df = processed_df.loc[processed_df.pui.isin(label_columns.pui), ['pui', 'abstract']].reset_index(drop=True)\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(len(label_columns)), test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "614ce50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df['abstract'] = abstracts_df['abstract'].apply(lambda x: [int(word_idx_dict[word]) for word in x.split(' ')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "252f2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_width = 250\n",
    "abstracts_df['abstract'] = abstracts_df['abstract'].apply(lambda x: x + [0] * (set_width - len(x)) if len(x) <= set_width else x[:set_width])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124d9958",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(abstracts_df\u001b[38;5;241m.\u001b[39mloc[train_indices, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\program files\\python39\\lib\\site-packages\\IPython\\core\\displayhook.py:258\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    255\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mseparate_out2)\n\u001b[0;32m    256\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Printing with history cache management.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    This is invoked every time the interpreter needs to print, and is\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    activated by setting the variable sys.displayhook to it.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_underscore()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.array(abstracts_df.loc[train_indices, 'abstract'].to_list(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3460fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = np.array(abstracts_df.loc[train_indices, 'abstract'].to_list(), dtype=int)\n",
    "X_tst = np.array(abstracts_df.loc[test_indices, 'abstract'].to_list(), dtype=int)\n",
    "\n",
    "\n",
    "Y_trn = label_columns.loc[train_indices, label_columns.columns.difference(['pui'])].to_numpy(dtype=int)\n",
    "Y_tst = label_columns.loc[test_indices, label_columns.columns.difference(['pui'])].to_numpy(dtype=int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6748b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0efe6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time 44.934 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_data = data_utils.TensorDataset(torch.from_numpy(X_trn).type(torch.LongTensor),\n",
    "                                      torch.from_numpy(Y_trn).type(torch.LongTensor))\n",
    "test_data = data_utils.TensorDataset(torch.from_numpy(X_tst).type(torch.LongTensor),\n",
    "                                     torch.from_numpy(Y_tst).type(torch.LongTensor))\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size, drop_last=False, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test_data, batch_size, drop_last=False)\n",
    "\n",
    "\n",
    "# train_loader, test_loader, vocabulary, X_tst, Y_tst, X_trn, Y_trn = load_data(data_path, sequence_length, vocab_size,\n",
    "#                                                                               batch_size)\n",
    "print('Process time %.3f (secs)\\n' % (timeit.default_timer() - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = embedding_weights.size(0)\n",
    "\n",
    "# create Network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55ec006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicModule, self).__init__()\n",
    "        self.model_name = str(type(self))\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "    def save(self, path=None):\n",
    "        if path is None:\n",
    "            raise ValueError('Please specify the saving road!!!')\n",
    "        torch.save(self.state_dict(), path)\n",
    "        return path\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def get_embedding_layer(embedding_weights):\n",
    "    word_embeddings = nn.Embedding(num_embeddings=embedding_weights.size(0), embedding_dim=embedding_weights.size(1))\n",
    "    word_embeddings.weight.data.copy_(embedding_weights)\n",
    "    word_embeddings.weight.requires_grad = False  # not train\n",
    "    return word_embeddings\n",
    "\n",
    "\n",
    "class Hybrid_XML(BasicModule):\n",
    "    def __init__(self, num_labels=3714, vocab_size=30001, embedding_size=300, embedding_weights=None,\n",
    "                 max_seq=300, hidden_size=256, d_a=256, label_emb=None):\n",
    "        super(Hybrid_XML, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_labels = num_labels\n",
    "        self.max_seq = max_seq\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if embedding_weights is None:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        else:\n",
    "            self.word_embeddings = get_embedding_layer(embedding_weights)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "        # interaction-attention layer\n",
    "        self.key_layer = torch.nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "        self.query_layer = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        # self-attn layer\n",
    "        self.linear_first = torch.nn.Linear(2 * self.hidden_size, d_a)\n",
    "        self.linear_second = torch.nn.Linear(d_a, self.num_labels)\n",
    "\n",
    "        # weight adaptive layer\n",
    "        self.linear_weight1 = torch.nn.Linear(2 * self.hidden_size, 1)\n",
    "        self.linear_weight2 = torch.nn.Linear(2 * self.hidden_size, 1)\n",
    "\n",
    "        # shared for all attention component\n",
    "        self.linear_final = torch.nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "        self.output_layer = torch.nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "        label_embedding = torch.FloatTensor(self.num_labels, self.hidden_size)\n",
    "        if label_emb is None:\n",
    "            nn.init.xavier_normal_(label_embedding)\n",
    "        else:\n",
    "            label_embedding.copy_(label_emb)\n",
    "        self.label_embedding = nn.Parameter(label_embedding, requires_grad=False)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if torch.cuda.is_available():\n",
    "            return (\n",
    "            torch.zeros(2, batch_size, self.hidden_size).cuda(), torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(2, batch_size, self.hidden_size), torch.zeros(2, batch_size, self.hidden_size))\n",
    "\n",
    "    def forward(self, x, embedding_generation=False):\n",
    "\n",
    "        emb = self.word_embeddings(x)\n",
    "\n",
    "        hidden_state = self.init_hidden(emb.size(0))\n",
    "        output, hidden_state = self.lstm(emb, hidden_state)  # [batch,seq,2*hidden]\n",
    "\n",
    "        # get attn_key\n",
    "        attn_key = self.key_layer(output)  # [batch,seq,hidden]\n",
    "        attn_key = attn_key.transpose(1, 2)  # [batch,hidden,seq]\n",
    "        # get attn_query\n",
    "        label_emb = self.label_embedding.expand(\n",
    "            (attn_key.size(0), self.label_embedding.size(0), self.label_embedding.size(1)))  # [batch,L,label_emb]\n",
    "        label_emb = self.query_layer(label_emb)  # [batch,L,label_emb]\n",
    "\n",
    "        # attention\n",
    "        similarity = torch.bmm(label_emb, attn_key)  # [batch,L,seq]\n",
    "        similarity = F.softmax(similarity, dim=2)\n",
    "\n",
    "        out1 = torch.bmm(similarity, output)  # [batch,L,label_emb]\n",
    "\n",
    "        # self-attn output\n",
    "        self_attn = torch.tanh(self.linear_first(output))  # [batch,seq,d_a]\n",
    "        self_attn = self.linear_second(self_attn)  # [batch,seq,L]\n",
    "        self_attn = F.softmax(self_attn, dim=1)\n",
    "        self_attn = self_attn.transpose(1, 2)  # [batch,L,seq]\n",
    "        out2 = torch.bmm(self_attn, output)  # [batch,L,hidden]\n",
    "\n",
    "        factor1 = torch.sigmoid(self.linear_weight1(out1))\n",
    "        factor2 = torch.sigmoid(self.linear_weight2(out2))\n",
    "        factor1 = factor1 / (factor1 + factor2)\n",
    "        factor2 = 1 - factor1\n",
    "\n",
    "        out = factor1 * out1 + factor2 * out2\n",
    "        \n",
    "        if embedding_generation:\n",
    "            return out\n",
    "        \n",
    "        out = F.relu(self.linear_final(out))\n",
    "        out = torch.sigmoid(self.output_layer(out).squeeze(-1))  # [batch,L]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7317d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_emb = np.zeros((52, 52))\n",
    "label_index_mapping = {}\n",
    "with open(cc_path(f'notebooks/label_embedding_test.txt')) as f:\n",
    "    for index, i in enumerate(f.readlines()):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        i = i.rstrip('\\n')\n",
    "        n = i.split(',')[0]\n",
    "        content = i.split(',')[1].split(' ')\n",
    "        label_index_mapping[index-1] = n\n",
    "        label_emb[index-1] = [float(value) for value in content]\n",
    "\n",
    "\n",
    "\n",
    "label_emb = torch.from_numpy(label_emb).float()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "add373d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hybrid_XML(num_labels=52, vocab_size=len(word_idx_dict), embedding_size=128, embedding_weights=embedding_weights,\n",
    "                   max_seq=250, hidden_size=52, d_a=256, label_emb=label_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e542bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid_XML(\n",
      "  (word_embeddings): Embedding(456010, 128)\n",
      "  (lstm): LSTM(128, 52, batch_first=True, bidirectional=True)\n",
      "  (key_layer): Linear(in_features=104, out_features=52, bias=True)\n",
      "  (query_layer): Linear(in_features=52, out_features=52, bias=True)\n",
      "  (linear_first): Linear(in_features=104, out_features=256, bias=True)\n",
      "  (linear_second): Linear(in_features=256, out_features=52, bias=True)\n",
      "  (linear_weight1): Linear(in_features=104, out_features=1, bias=True)\n",
      "  (linear_weight2): Linear(in_features=104, out_features=1, bias=True)\n",
      "  (linear_final): Linear(in_features=104, out_features=52, bias=True)\n",
      "  (output_layer): Linear(in_features=52, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b01479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----epoch:  1---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:24<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 训练结束 : avg_loss = 12.4208\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:10<00:00, 35.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 测试结束 : avg_loss = 11.7889\n",
      "precision@1 : 72.9938 , precision@3 : 61.4246 , precision@5 : 56.1730 \n",
      "ndcg@1 : 72.9938 , ndcg@3 : 68.0398 , ndcg@5 : 67.0103 \n",
      "----epoch:  2---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:28<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 训练结束 : avg_loss = 11.6842\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:11<00:00, 32.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 测试结束 : avg_loss = 11.2605\n",
      "precision@1 : 74.3892 , precision@3 : 63.7980 , precision@5 : 57.6450 \n",
      "ndcg@1 : 74.3892 , ndcg@3 : 71.2822 , ndcg@5 : 70.2122 \n",
      "----epoch:  3---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:29<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 训练结束 : avg_loss = 11.1208\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:11<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 测试结束 : avg_loss = 10.9138\n",
      "precision@1 : 77.2901 , precision@3 : 65.4897 , precision@5 : 58.3980 \n",
      "ndcg@1 : 77.2901 , ndcg@3 : 73.2229 , ndcg@5 : 71.5373 \n",
      "----epoch:  4---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:28<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 训练结束 : avg_loss = 10.8983\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:11<00:00, 33.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 测试结束 : avg_loss = 10.7643\n",
      "precision@1 : 78.4920 , precision@3 : 66.2859 , precision@5 : 58.9018 \n",
      "ndcg@1 : 78.4920 , ndcg@3 : 74.2263 , ndcg@5 : 72.3180 \n",
      "----epoch:  5---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:29<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 训练结束 : avg_loss = 10.7665\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:11<00:00, 31.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 测试结束 : avg_loss = 10.6720\n",
      "precision@1 : 78.9561 , precision@3 : 66.5224 , precision@5 : 59.1096 \n",
      "ndcg@1 : 78.9561 , ndcg@3 : 74.3024 , ndcg@5 : 72.2541 \n",
      "----epoch:  6---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:30<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 训练结束 : avg_loss = 10.6525\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:11<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 测试结束 : avg_loss = 10.6800\n",
      "precision@1 : 78.2975 , precision@3 : 66.7031 , precision@5 : 59.0815 \n",
      "ndcg@1 : 78.2975 , ndcg@3 : 74.1249 , ndcg@5 : 71.8912 \n",
      "----epoch:  7---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:31<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7 训练结束 : avg_loss = 10.5681\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7 测试结束 : avg_loss = 10.4752\n",
      "precision@1 : 79.9694 , precision@3 : 67.1019 , precision@5 : 59.4096 \n",
      "ndcg@1 : 79.9694 , ndcg@3 : 75.3379 , ndcg@5 : 73.2547 \n",
      "----epoch:  8---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8 训练结束 : avg_loss = 10.4781\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8 测试结束 : avg_loss = 10.4988\n",
      "precision@1 : 79.7536 , precision@3 : 67.3801 , precision@5 : 59.6583 \n",
      "ndcg@1 : 79.7536 , ndcg@3 : 75.1389 , ndcg@5 : 72.9069 \n",
      "----epoch:  9---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:32<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9 训练结束 : avg_loss = 10.3904\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9 测试结束 : avg_loss = 10.3306\n",
      "precision@1 : 80.3384 , precision@3 : 67.4255 , precision@5 : 59.7942 \n",
      "ndcg@1 : 80.3384 , ndcg@3 : 75.6507 , ndcg@5 : 73.5753 \n",
      "----epoch: 10---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:32<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 训练结束 : avg_loss = 10.3090\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 测试结束 : avg_loss = 10.2224\n",
      "precision@1 : 80.7416 , precision@3 : 68.1001 , precision@5 : 60.2770 \n",
      "ndcg@1 : 80.7416 , ndcg@3 : 76.2651 , ndcg@5 : 74.0426 \n",
      "----epoch: 11---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:31<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 训练结束 : avg_loss = 10.2308\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 30.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 测试结束 : avg_loss = 10.1618\n",
      "precision@1 : 80.8890 , precision@3 : 68.2534 , precision@5 : 60.4448 \n",
      "ndcg@1 : 80.8890 , ndcg@3 : 76.3382 , ndcg@5 : 74.0944 \n",
      "----epoch: 12---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:29<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 训练结束 : avg_loss = 10.1577\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 测试结束 : avg_loss = 10.0875\n",
      "precision@1 : 81.3546 , precision@3 : 68.5647 , precision@5 : 60.5845 \n",
      "ndcg@1 : 81.3546 , ndcg@3 : 76.7027 , ndcg@5 : 74.3477 \n",
      "----epoch: 13---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:32<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 训练结束 : avg_loss = 10.0927\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 测试结束 : avg_loss = 10.1147\n",
      "precision@1 : 81.5675 , precision@3 : 68.5547 , precision@5 : 60.6591 \n",
      "ndcg@1 : 81.5675 , ndcg@3 : 76.6526 , ndcg@5 : 74.3244 \n",
      "----epoch: 14---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 训练结束 : avg_loss = 9.9396\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 测试结束 : avg_loss = 9.9294\n",
      "precision@1 : 81.9550 , precision@3 : 69.0794 , precision@5 : 61.0275 \n",
      "ndcg@1 : 81.9550 , ndcg@3 : 77.3050 , ndcg@5 : 74.9597 \n",
      "----epoch: 15---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 训练结束 : avg_loss = 9.9150\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 测试结束 : avg_loss = 9.9143\n",
      "precision@1 : 82.0329 , precision@3 : 69.1366 , precision@5 : 61.0752 \n",
      "ndcg@1 : 82.0329 , ndcg@3 : 77.3929 , ndcg@5 : 75.0896 \n",
      "----epoch: 16---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 训练结束 : avg_loss = 9.8998\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 测试结束 : avg_loss = 9.9029\n",
      "precision@1 : 81.9635 , precision@3 : 69.2067 , precision@5 : 61.1317 \n",
      "ndcg@1 : 81.9635 , ndcg@3 : 77.4131 , ndcg@5 : 75.0747 \n",
      "----epoch: 17---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:35<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 训练结束 : avg_loss = 9.8871\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 测试结束 : avg_loss = 9.9025\n",
      "precision@1 : 82.1152 , precision@3 : 69.1683 , precision@5 : 61.1731 \n",
      "ndcg@1 : 82.1152 , ndcg@3 : 77.3728 , ndcg@5 : 75.0942 \n",
      "----epoch: 18---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 训练结束 : avg_loss = 9.8752\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 测试结束 : avg_loss = 9.8872\n",
      "precision@1 : 82.1295 , precision@3 : 69.2090 , precision@5 : 61.1862 \n",
      "ndcg@1 : 82.1295 , ndcg@3 : 77.5071 , ndcg@5 : 75.2291 \n",
      "----epoch: 19---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 训练结束 : avg_loss = 9.8633\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 测试结束 : avg_loss = 9.8741\n",
      "precision@1 : 82.1508 , precision@3 : 69.2653 , precision@5 : 61.2143 \n",
      "ndcg@1 : 82.1508 , ndcg@3 : 77.3944 , ndcg@5 : 75.0671 \n",
      "----epoch: 20---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 训练结束 : avg_loss = 9.8527\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 测试结束 : avg_loss = 9.8612\n",
      "precision@1 : 82.2530 , precision@3 : 69.4110 , precision@5 : 61.3034 \n",
      "ndcg@1 : 82.2530 , ndcg@3 : 77.6158 , ndcg@5 : 75.2576 \n",
      "----epoch: 21---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 训练结束 : avg_loss = 9.8425\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 测试结束 : avg_loss = 9.8495\n",
      "precision@1 : 82.2743 , precision@3 : 69.4153 , precision@5 : 61.3247 \n",
      "ndcg@1 : 82.2743 , ndcg@3 : 77.6679 , ndcg@5 : 75.3419 \n",
      "----epoch: 22---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 训练结束 : avg_loss = 9.8299\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 测试结束 : avg_loss = 9.8341\n",
      "precision@1 : 82.3126 , precision@3 : 69.5317 , precision@5 : 61.4087 \n",
      "ndcg@1 : 82.3126 , ndcg@3 : 77.7796 , ndcg@5 : 75.4545 \n",
      "----epoch: 23---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 训练结束 : avg_loss = 9.8210\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 测试结束 : avg_loss = 9.8539\n",
      "precision@1 : 82.3182 , precision@3 : 69.5231 , precision@5 : 61.3979 \n",
      "ndcg@1 : 82.3182 , ndcg@3 : 77.6753 , ndcg@5 : 75.3132 \n",
      "----epoch: 24---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 训练结束 : avg_loss = 9.8081\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 测试结束 : avg_loss = 9.8194\n",
      "precision@1 : 82.2841 , precision@3 : 69.6211 , precision@5 : 61.4666 \n",
      "ndcg@1 : 82.2841 , ndcg@3 : 77.8285 , ndcg@5 : 75.4726 \n",
      "----epoch: 25---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:35<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 训练结束 : avg_loss = 9.7988\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 测试结束 : avg_loss = 9.8066\n",
      "precision@1 : 82.4161 , precision@3 : 69.6608 , precision@5 : 61.5183 \n",
      "ndcg@1 : 82.4161 , ndcg@3 : 77.8831 , ndcg@5 : 75.5430 \n",
      "----epoch: 26---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 训练结束 : avg_loss = 9.7882\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 测试结束 : avg_loss = 9.7955\n",
      "precision@1 : 82.3962 , precision@3 : 69.7123 , precision@5 : 61.5535 \n",
      "ndcg@1 : 82.3962 , ndcg@3 : 77.9407 , ndcg@5 : 75.5951 \n",
      "----epoch: 27---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 训练结束 : avg_loss = 9.7789\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 测试结束 : avg_loss = 9.7890\n",
      "precision@1 : 82.4132 , precision@3 : 69.8230 , precision@5 : 61.5438 \n",
      "ndcg@1 : 82.4132 , ndcg@3 : 78.0716 , ndcg@5 : 75.6465 \n",
      "----epoch: 28---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 训练结束 : avg_loss = 9.7683\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 测试结束 : avg_loss = 9.7765\n",
      "precision@1 : 82.4672 , precision@3 : 69.8354 , precision@5 : 61.6006 \n",
      "ndcg@1 : 82.4672 , ndcg@3 : 78.0395 , ndcg@5 : 75.6501 \n",
      "----epoch: 29---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 训练结束 : avg_loss = 9.7600\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 28.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 测试结束 : avg_loss = 9.7692\n",
      "precision@1 : 82.4970 , precision@3 : 69.8462 , precision@5 : 61.6151 \n",
      "ndcg@1 : 82.4970 , ndcg@3 : 78.0171 , ndcg@5 : 75.6232 \n",
      "----epoch: 30---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:43<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 训练结束 : avg_loss = 9.7464\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 测试结束 : avg_loss = 9.7881\n",
      "precision@1 : 82.4558 , precision@3 : 69.7952 , precision@5 : 61.5475 \n",
      "ndcg@1 : 82.4558 , ndcg@3 : 77.9681 , ndcg@5 : 75.5181 \n",
      "----epoch: 31---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:41<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 训练结束 : avg_loss = 9.7382\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 测试结束 : avg_loss = 9.7496\n",
      "precision@1 : 82.6005 , precision@3 : 69.9508 , precision@5 : 61.7269 \n",
      "ndcg@1 : 82.6005 , ndcg@3 : 78.1934 , ndcg@5 : 75.8122 \n",
      "----epoch: 32---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:35<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 训练结束 : avg_loss = 9.7305\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 测试结束 : avg_loss = 9.7385\n",
      "precision@1 : 82.6758 , precision@3 : 69.9957 , precision@5 : 61.7326 \n",
      "ndcg@1 : 82.6758 , ndcg@3 : 78.2700 , ndcg@5 : 75.8510 \n",
      "----epoch: 33---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 训练结束 : avg_loss = 9.7222\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 测试结束 : avg_loss = 9.7340\n",
      "precision@1 : 82.6716 , precision@3 : 70.0241 , precision@5 : 61.7857 \n",
      "ndcg@1 : 82.6716 , ndcg@3 : 78.2629 , ndcg@5 : 75.8898 \n",
      "----epoch: 34---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 训练结束 : avg_loss = 9.7111\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 测试结束 : avg_loss = 9.7215\n",
      "precision@1 : 82.6388 , precision@3 : 70.0539 , precision@5 : 61.8058 \n",
      "ndcg@1 : 82.6388 , ndcg@3 : 78.3083 , ndcg@5 : 75.9067 \n",
      "----epoch: 35---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 训练结束 : avg_loss = 9.7026\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 测试结束 : avg_loss = 9.7523\n",
      "precision@1 : 82.4204 , precision@3 : 69.8392 , precision@5 : 61.7087 \n",
      "ndcg@1 : 82.4204 , ndcg@3 : 77.9481 , ndcg@5 : 75.5696 \n",
      "----epoch: 36---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 训练结束 : avg_loss = 9.6967\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 测试结束 : avg_loss = 9.7155\n",
      "precision@1 : 82.6588 , precision@3 : 70.1107 , precision@5 : 61.8390 \n",
      "ndcg@1 : 82.6588 , ndcg@3 : 78.3156 , ndcg@5 : 75.8879 \n",
      "----epoch: 37---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 训练结束 : avg_loss = 9.6887\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 测试结束 : avg_loss = 9.7132\n",
      "precision@1 : 82.6984 , precision@3 : 70.1608 , precision@5 : 61.8643 \n",
      "ndcg@1 : 82.6984 , ndcg@3 : 78.3987 , ndcg@5 : 75.9770 \n",
      "----epoch: 38---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 训练结束 : avg_loss = 9.6780\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 测试结束 : avg_loss = 9.6891\n",
      "precision@1 : 82.7993 , precision@3 : 70.1778 , precision@5 : 61.8697 \n",
      "ndcg@1 : 82.7993 , ndcg@3 : 78.4590 , ndcg@5 : 76.0177 \n",
      "----epoch: 39---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 训练结束 : avg_loss = 9.6711\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 28.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 测试结束 : avg_loss = 9.6919\n",
      "precision@1 : 82.7993 , precision@3 : 70.1774 , precision@5 : 61.8700 \n",
      "ndcg@1 : 82.7993 , ndcg@3 : 78.5049 , ndcg@5 : 76.1086 \n",
      "----epoch: 40---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 训练结束 : avg_loss = 9.6605\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 测试结束 : avg_loss = 9.7172\n",
      "precision@1 : 82.5452 , precision@3 : 70.1963 , precision@5 : 61.8483 \n",
      "ndcg@1 : 82.5452 , ndcg@3 : 78.3585 , ndcg@5 : 75.8742 \n",
      "----epoch: 41---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:35<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 训练结束 : avg_loss = 9.6535\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 测试结束 : avg_loss = 9.6627\n",
      "precision@1 : 82.8389 , precision@3 : 70.3236 , precision@5 : 61.9676 \n",
      "ndcg@1 : 82.8389 , ndcg@3 : 78.5688 , ndcg@5 : 76.1009 \n",
      "----epoch: 42---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 训练结束 : avg_loss = 9.6440\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:13<00:00, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 测试结束 : avg_loss = 9.6591\n",
      "precision@1 : 82.8887 , precision@3 : 70.3491 , precision@5 : 61.9468 \n",
      "ndcg@1 : 82.8887 , ndcg@3 : 78.6131 , ndcg@5 : 76.1224 \n",
      "----epoch: 43---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 训练结束 : avg_loss = 9.6376\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 测试结束 : avg_loss = 9.6539\n",
      "precision@1 : 83.0930 , precision@3 : 70.4272 , precision@5 : 62.0632 \n",
      "ndcg@1 : 83.0930 , ndcg@3 : 78.7855 , ndcg@5 : 76.3322 \n",
      "----epoch: 44---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:34<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 训练结束 : avg_loss = 9.6296\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 测试结束 : avg_loss = 9.6574\n",
      "precision@1 : 82.8661 , precision@3 : 70.3586 , precision@5 : 62.0087 \n",
      "ndcg@1 : 82.8661 , ndcg@3 : 78.6042 , ndcg@5 : 76.1524 \n",
      "----epoch: 45---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1467/1467 [01:33<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 训练结束 : avg_loss = 9.6199\n",
      "开始进行validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:12<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 测试结束 : avg_loss = 9.6712\n",
      "precision@1 : 82.9853 , precision@3 : 70.3893 , precision@5 : 61.9852 \n",
      "ndcg@1 : 82.9853 , ndcg@3 : 78.7177 , ndcg@5 : 76.2462 \n",
      "----epoch: 46---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   9%|▊         | 128/1467 [00:08<01:26, 15.52it/s]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=4e-5)\n",
    "criterion = torch.nn.BCELoss(reduction='sum')\n",
    "epoch = 100\n",
    "best_acc = 0.0\n",
    "pre_acc = 0.0\n",
    "\n",
    "# if not os.path.isdir('./rcv_log'):\n",
    "#     os.makedirs('./rcv_log')\n",
    "# trace_file='./rcv_log/trace_rcv.txt'\n",
    "\n",
    "for ep in range(1, epoch + 1):\n",
    "    train_loss = 0\n",
    "    print(\"----epoch: %2d---- \" % ep)\n",
    "    model.train()\n",
    "    for i, (data, labels) in enumerate(tqdm(train_loader, desc='Batch: ')):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # data = data.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, labels.float()) / pred.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += float(loss)\n",
    "    batch_num = i + 1\n",
    "    train_loss /= batch_num\n",
    "\n",
    "    print(\"epoch %2d 训练结束 : avg_loss = %.4f\" % (ep, train_loss))\n",
    "    print(\"开始进行validation\")\n",
    "    test_loss = 0\n",
    "    test_p1, test_p3, test_p5 = 0, 0, 0\n",
    "    test_ndcg1, test_ndcg3, test_ndcg5 = 0, 0, 0\n",
    "    model.eval()\n",
    "    for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
    "        # data = data.cuda()\n",
    "        # labels = labels.cuda()\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, labels.float()) / pred.size(0)\n",
    "\n",
    "        # 计算metric\n",
    "        labels_cpu = labels.data.cpu()\n",
    "        pred_cpu = pred.data.cpu()\n",
    "\n",
    "        _p1, _p3, _p5 = precision_k(pred_cpu.topk(k=5)[1].numpy(), labels_cpu.numpy(), k=[1, 3, 5])\n",
    "        test_p1 += _p1\n",
    "        test_p3 += _p3\n",
    "        test_p5 += _p5\n",
    "\n",
    "        _ndcg1, _ndcg3, _ndcg5 = ndcg_k(pred_cpu.topk(k=5)[1].numpy(), labels_cpu.numpy(), k=[1, 3, 5])\n",
    "        test_ndcg1 += _ndcg1\n",
    "        test_ndcg3 += _ndcg3\n",
    "        test_ndcg5 += _ndcg5\n",
    "\n",
    "        test_loss += float(loss)\n",
    "    batch_num = i + 1\n",
    "    test_loss /= batch_num\n",
    "\n",
    "    test_p1 /= batch_num\n",
    "    test_p3 /= batch_num\n",
    "    test_p5 /= batch_num\n",
    "\n",
    "    test_ndcg1 /= batch_num\n",
    "    test_ndcg3 /= batch_num\n",
    "    test_ndcg5 /= batch_num\n",
    "\n",
    "    print(\"epoch %2d 测试结束 : avg_loss = %.4f\" % (ep, test_loss))\n",
    "    print(\"precision@1 : %.4f , precision@3 : %.4f , precision@5 : %.4f \" % (test_p1, test_p3, test_p5))\n",
    "    print(\"ndcg@1 : %.4f , ndcg@3 : %.4f , ndcg@5 : %.4f \" % (test_ndcg1, test_ndcg3, test_ndcg5))\n",
    "\n",
    "    if test_p3 < pre_acc:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0001\n",
    "    pre_acc = test_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80dcedcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[141632, 236289, 428078,  ...,      0,      0,      0],\n",
      "        [385728,  70288,  84518,  ...,      0,      0,      0],\n",
      "        [  4558, 345890, 205374,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [303372, 199293, 386063,  ...,      0,      0,      0],\n",
      "        [  1822, 431470, 299190,  ...,      0,      0,      0],\n",
      "        [197196, 378696, 376918,  ...,      0,      0,      0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 52, 104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(data, embedding_generation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
    "    print(data)\n",
    "    pred = model(data, embedding_generation=True)\n",
    "    print(pred.detach().numpy().shape)\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63a92e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, cc_path(f'models/xml_embedding/word_embeddings_{pretrain}_20230408_all_data.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc652522-769a-4759-9f31-20daddcd2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(cc_path(f'models/xml_embedding/word_embeddings_{pretrain}_20230408_all_data.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3166a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "del embedding_df, processed_df, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da81aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_batch_size = 1024\n",
    "abstracts_to_embed = np.array(abstracts_df.loc[:, 'abstract'].to_list(), dtype=int)\n",
    "puis_to_embed = np.array(abstracts_df.loc[:, 'pui'].to_list(), dtype=int)\n",
    "\n",
    "embedding_data = data_utils.TensorDataset(torch.from_numpy(abstracts_to_embed).type(torch.LongTensor), \n",
    "                                          torch.from_numpy(puis_to_embed).type(torch.LongTensor))\n",
    "final_data = data_utils.DataLoader(embedding_data, emb_batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "192bbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2a57370-9ae7-4225-b9f4-bc523d4bbe43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117310"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts_df['pui'].to_numpy(dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1b9ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [04:51<00:00,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "num_of_embedding_dim = 104\n",
    "\n",
    "embedding_columns =  [f'd_{i}' for i in range(52)]\n",
    "xml_embedding_df = pd.DataFrame(columns=embedding_columns, index=abstracts_df['pui'].to_numpy(dtype=int))\n",
    "# xml_embedding_df['embedding'] = xml_embedding_df['embedding'].astype(object)\n",
    "np.set_printoptions(threshold = 100000000000000)\n",
    "\n",
    "for i, (data, pui) in enumerate(tqdm(final_data)):\n",
    "    pred = model(data, embedding_generation=True)\n",
    "    \n",
    "    right_puis =  list(pui.detach().numpy())\n",
    "    \n",
    "    numpy_preds = pred.detach().numpy()\n",
    "    for idx_batch in range(numpy_preds.shape[0]):\n",
    "        for idx_label in range(numpy_preds.shape[1]):\n",
    "            xml_embedding_df.loc[right_puis[idx_batch], embedding_columns[idx_label]] = numpy_preds[idx_batch, \n",
    "                                                                                             idx_label, \n",
    "                                                                                             :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5eb9a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_embedding_df.reset_index(names='pui', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ddde897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_embedding_df.to_feather(cc_path('data/processed/canary/embeddings_xml.ftr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c3eb69c-5e4e-4b0b-a91d-edc62b635922",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.width = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b088b0b-49e6-4ed4-8a88-6d6e32c90241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_0</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>...</th>\n",
       "      <th>d_42</th>\n",
       "      <th>d_43</th>\n",
       "      <th>d_44</th>\n",
       "      <th>d_45</th>\n",
       "      <th>d_46</th>\n",
       "      <th>d_47</th>\n",
       "      <th>d_48</th>\n",
       "      <th>d_49</th>\n",
       "      <th>d_50</th>\n",
       "      <th>d_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624531411</th>\n",
       "      <td>[-0.016383378, -0.11197758, -0.037253555, -0.2...</td>\n",
       "      <td>[0.010617012, -0.09705223, -0.01200425, -0.120...</td>\n",
       "      <td>[0.028110279, -0.08243386, -0.016131265, -0.18...</td>\n",
       "      <td>[0.0022158436, -0.11320748, -0.010183357, -0.1...</td>\n",
       "      <td>[0.005926796, -0.10500478, -0.010475147, -0.12...</td>\n",
       "      <td>[0.0113420375, -0.09601049, -0.014044623, -0.1...</td>\n",
       "      <td>[0.016601732, -0.09619771, -0.009100688, -0.14...</td>\n",
       "      <td>[0.11544543, -0.005443737, -0.005527966, -0.18...</td>\n",
       "      <td>[0.02586015, -0.086351044, -0.010884014, -0.16...</td>\n",
       "      <td>[0.009882777, -0.09707534, -0.021866538, -0.18...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.18155344, 0.026362767, -0.01475883, -0.2147...</td>\n",
       "      <td>[0.0069437977, -0.09799223, -0.02816795, -0.23...</td>\n",
       "      <td>[0.18892401, 0.041114308, -0.00097465096, -0.1...</td>\n",
       "      <td>[0.11469094, -0.015334345, 0.006475803, -0.087...</td>\n",
       "      <td>[0.027374564, -0.08158906, -0.01762917, -0.206...</td>\n",
       "      <td>[0.04705087, -0.065758094, -0.018019354, -0.21...</td>\n",
       "      <td>[0.3474198, 0.15047382, 0.0039090053, -0.13961...</td>\n",
       "      <td>[0.11787519, -0.0064049475, -0.0025091413, -0....</td>\n",
       "      <td>[0.069682136, -0.054890573, -0.011223326, -0.1...</td>\n",
       "      <td>[-0.011351064, -0.100169934, -0.034848228, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625340088</th>\n",
       "      <td>[0.06821822, -0.05620522, -0.065800205, -0.222...</td>\n",
       "      <td>[0.10693053, -0.017095909, -0.044121563, -0.09...</td>\n",
       "      <td>[0.10340122, -0.019759048, -0.055330824, -0.16...</td>\n",
       "      <td>[0.044841465, -0.09599258, -0.047074445, -0.14...</td>\n",
       "      <td>[0.042860292, -0.08393292, -0.043275695, -0.10...</td>\n",
       "      <td>[0.038487554, -0.07838504, -0.053617507, -0.16...</td>\n",
       "      <td>[0.05473292, -0.075368986, -0.042547263, -0.12...</td>\n",
       "      <td>[0.18368945, 0.09457679, -0.079515636, -0.1797...</td>\n",
       "      <td>[0.1327912, 0.019922812, -0.06676929, -0.15574...</td>\n",
       "      <td>[0.1424106, 0.018941574, -0.052223623, -0.1458...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.24319527, 0.12634419, -0.05570019, -0.18991...</td>\n",
       "      <td>[0.12861286, 0.009207115, -0.063367575, -0.198...</td>\n",
       "      <td>[0.24438602, 0.14896263, -0.07208059, -0.14055...</td>\n",
       "      <td>[0.1749304, 0.08700106, -0.05070314, -0.066946...</td>\n",
       "      <td>[0.100104034, -0.02964319, -0.0711903, -0.2004...</td>\n",
       "      <td>[0.13491955, 0.01794957, -0.067108504, -0.1916...</td>\n",
       "      <td>[0.41909015, 0.33678198, -0.07781066, -0.12629...</td>\n",
       "      <td>[0.17230125, 0.06469397, -0.08423577, -0.16590...</td>\n",
       "      <td>[0.15537813, 0.036530755, -0.06381854, -0.1704...</td>\n",
       "      <td>[0.02809963, -0.08056283, -0.07836892, -0.2682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625805682</th>\n",
       "      <td>[0.028528668, -0.060206894, 0.07548873, -0.348...</td>\n",
       "      <td>[0.042353593, -0.07522996, 0.045501076, -0.324...</td>\n",
       "      <td>[0.043712128, -0.07069669, 0.053283475, -0.341...</td>\n",
       "      <td>[0.0912251, -0.05125811, 0.106232695, -0.31711...</td>\n",
       "      <td>[0.071796775, -0.050604787, 0.09280021, -0.337...</td>\n",
       "      <td>[0.076959535, -0.04865962, 0.090105645, -0.341...</td>\n",
       "      <td>[0.077228464, -0.051366046, 0.099378556, -0.32...</td>\n",
       "      <td>[0.051017053, -0.06567388, 0.10099919, -0.2431...</td>\n",
       "      <td>[0.04003511, -0.047263972, 0.09858238, -0.3281...</td>\n",
       "      <td>[0.054769102, -0.05078943, 0.08115368, -0.2868...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.18210159, 0.063631855, 0.05955499, -0.32273...</td>\n",
       "      <td>[0.057935737, -0.034007467, 0.08288933, -0.324...</td>\n",
       "      <td>[0.21283509, 0.080757335, 0.084314525, -0.2392...</td>\n",
       "      <td>[0.099942975, -0.049863294, 0.13453224, -0.256...</td>\n",
       "      <td>[0.046176944, -0.0769093, 0.06805101, -0.29428...</td>\n",
       "      <td>[0.037154716, -0.05500753, 0.088356555, -0.317...</td>\n",
       "      <td>[0.33445185, 0.20716941, 0.06621084, -0.234082...</td>\n",
       "      <td>[0.07703457, -0.032216277, 0.1353079, -0.22812...</td>\n",
       "      <td>[0.06902366, -0.051700268, 0.06834428, -0.3177...</td>\n",
       "      <td>[0.03009884, -0.06154553, 0.08346843, -0.34348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626662493</th>\n",
       "      <td>[0.059955165, -0.02994335, -0.03311316, -0.143...</td>\n",
       "      <td>[0.10139962, 0.009669423, -0.022478202, -0.038...</td>\n",
       "      <td>[0.0790334, -0.01266022, -0.02287779, -0.10124...</td>\n",
       "      <td>[0.030228794, -0.07793985, -0.028091416, -0.13...</td>\n",
       "      <td>[0.036995795, -0.06270175, -0.0315825, -0.1039...</td>\n",
       "      <td>[0.027064249, -0.0709749, -0.031441428, -0.146...</td>\n",
       "      <td>[0.043158136, -0.059222713, -0.027855176, -0.1...</td>\n",
       "      <td>[0.13726412, 0.05951462, 0.010710327, -0.14864...</td>\n",
       "      <td>[0.083741456, 0.0010779575, 0.00037083589, -0....</td>\n",
       "      <td>[0.12572579, 0.037525304, -0.019792218, -0.073...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.15025625, 0.0521947, -0.026349314, -0.17327...</td>\n",
       "      <td>[0.11670811, 0.030976295, -0.02641234, -0.1190...</td>\n",
       "      <td>[0.19017154, 0.094812796, -0.003392328, -0.117...</td>\n",
       "      <td>[0.13538006, 0.04384046, 0.006757291, -0.05630...</td>\n",
       "      <td>[0.07334437, -0.024985045, -0.021543493, -0.13...</td>\n",
       "      <td>[0.097782776, 0.006623201, -0.026629627, -0.12...</td>\n",
       "      <td>[0.3373683, 0.24063022, -0.0021311226, -0.1236...</td>\n",
       "      <td>[0.15725388, 0.042757872, -0.008270113, -0.101...</td>\n",
       "      <td>[0.12123768, 0.029323883, -0.025152106, -0.115...</td>\n",
       "      <td>[0.022587577, -0.067165665, -0.03826805, -0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626822402</th>\n",
       "      <td>[0.27494726, -0.061647326, 0.18791562, -0.2993...</td>\n",
       "      <td>[0.3305084, -0.046140015, 0.18127444, -0.38189...</td>\n",
       "      <td>[0.30549046, -0.052407146, 0.18561853, -0.3563...</td>\n",
       "      <td>[0.33089703, -0.05900829, 0.19056454, -0.28315...</td>\n",
       "      <td>[0.3212989, -0.053632278, 0.18682936, -0.28965...</td>\n",
       "      <td>[0.33208808, -0.05664587, 0.18075578, -0.28696...</td>\n",
       "      <td>[0.32238388, -0.05355747, 0.18911934, -0.28512...</td>\n",
       "      <td>[0.2843451, -0.075362384, 0.17306942, -0.26655...</td>\n",
       "      <td>[0.26771063, -0.066218354, 0.17441167, -0.2618...</td>\n",
       "      <td>[0.28459507, -0.07167025, 0.17930306, -0.29999...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.34554872, -0.114436746, 0.16829908, -0.2782...</td>\n",
       "      <td>[0.25267428, -0.080995634, 0.17711401, -0.2627...</td>\n",
       "      <td>[0.3340537, -0.093892336, 0.1561747, -0.314642...</td>\n",
       "      <td>[0.3147732, -0.065012425, 0.17388539, -0.25686...</td>\n",
       "      <td>[0.29047766, -0.05335179, 0.18333776, -0.34369...</td>\n",
       "      <td>[0.2530854, -0.07009541, 0.18177888, -0.267674...</td>\n",
       "      <td>[0.3673926, -0.15189306, 0.14653346, -0.250014...</td>\n",
       "      <td>[0.27901053, -0.060020022, 0.20105505, -0.2875...</td>\n",
       "      <td>[0.2838174, -0.074696735, 0.17902729, -0.29193...</td>\n",
       "      <td>[0.25677127, -0.058577746, 0.19382006, -0.2792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011621972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011622024</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011622065</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011626864</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011632199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117310 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          d_0   \n",
       "624531411   [-0.016383378, -0.11197758, -0.037253555, -0.2...  \\\n",
       "625340088   [0.06821822, -0.05620522, -0.065800205, -0.222...   \n",
       "625805682   [0.028528668, -0.060206894, 0.07548873, -0.348...   \n",
       "626662493   [0.059955165, -0.02994335, -0.03311316, -0.143...   \n",
       "626822402   [0.27494726, -0.061647326, 0.18791562, -0.2993...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_1   \n",
       "624531411   [0.010617012, -0.09705223, -0.01200425, -0.120...  \\\n",
       "625340088   [0.10693053, -0.017095909, -0.044121563, -0.09...   \n",
       "625805682   [0.042353593, -0.07522996, 0.045501076, -0.324...   \n",
       "626662493   [0.10139962, 0.009669423, -0.022478202, -0.038...   \n",
       "626822402   [0.3305084, -0.046140015, 0.18127444, -0.38189...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_2   \n",
       "624531411   [0.028110279, -0.08243386, -0.016131265, -0.18...  \\\n",
       "625340088   [0.10340122, -0.019759048, -0.055330824, -0.16...   \n",
       "625805682   [0.043712128, -0.07069669, 0.053283475, -0.341...   \n",
       "626662493   [0.0790334, -0.01266022, -0.02287779, -0.10124...   \n",
       "626822402   [0.30549046, -0.052407146, 0.18561853, -0.3563...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_3   \n",
       "624531411   [0.0022158436, -0.11320748, -0.010183357, -0.1...  \\\n",
       "625340088   [0.044841465, -0.09599258, -0.047074445, -0.14...   \n",
       "625805682   [0.0912251, -0.05125811, 0.106232695, -0.31711...   \n",
       "626662493   [0.030228794, -0.07793985, -0.028091416, -0.13...   \n",
       "626822402   [0.33089703, -0.05900829, 0.19056454, -0.28315...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_4   \n",
       "624531411   [0.005926796, -0.10500478, -0.010475147, -0.12...  \\\n",
       "625340088   [0.042860292, -0.08393292, -0.043275695, -0.10...   \n",
       "625805682   [0.071796775, -0.050604787, 0.09280021, -0.337...   \n",
       "626662493   [0.036995795, -0.06270175, -0.0315825, -0.1039...   \n",
       "626822402   [0.3212989, -0.053632278, 0.18682936, -0.28965...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_5   \n",
       "624531411   [0.0113420375, -0.09601049, -0.014044623, -0.1...  \\\n",
       "625340088   [0.038487554, -0.07838504, -0.053617507, -0.16...   \n",
       "625805682   [0.076959535, -0.04865962, 0.090105645, -0.341...   \n",
       "626662493   [0.027064249, -0.0709749, -0.031441428, -0.146...   \n",
       "626822402   [0.33208808, -0.05664587, 0.18075578, -0.28696...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_6   \n",
       "624531411   [0.016601732, -0.09619771, -0.009100688, -0.14...  \\\n",
       "625340088   [0.05473292, -0.075368986, -0.042547263, -0.12...   \n",
       "625805682   [0.077228464, -0.051366046, 0.099378556, -0.32...   \n",
       "626662493   [0.043158136, -0.059222713, -0.027855176, -0.1...   \n",
       "626822402   [0.32238388, -0.05355747, 0.18911934, -0.28512...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_7   \n",
       "624531411   [0.11544543, -0.005443737, -0.005527966, -0.18...  \\\n",
       "625340088   [0.18368945, 0.09457679, -0.079515636, -0.1797...   \n",
       "625805682   [0.051017053, -0.06567388, 0.10099919, -0.2431...   \n",
       "626662493   [0.13726412, 0.05951462, 0.010710327, -0.14864...   \n",
       "626822402   [0.2843451, -0.075362384, 0.17306942, -0.26655...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_8   \n",
       "624531411   [0.02586015, -0.086351044, -0.010884014, -0.16...  \\\n",
       "625340088   [0.1327912, 0.019922812, -0.06676929, -0.15574...   \n",
       "625805682   [0.04003511, -0.047263972, 0.09858238, -0.3281...   \n",
       "626662493   [0.083741456, 0.0010779575, 0.00037083589, -0....   \n",
       "626822402   [0.26771063, -0.066218354, 0.17441167, -0.2618...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                          d_9  ...   \n",
       "624531411   [0.009882777, -0.09707534, -0.021866538, -0.18...  ...  \\\n",
       "625340088   [0.1424106, 0.018941574, -0.052223623, -0.1458...  ...   \n",
       "625805682   [0.054769102, -0.05078943, 0.08115368, -0.2868...  ...   \n",
       "626662493   [0.12572579, 0.037525304, -0.019792218, -0.073...  ...   \n",
       "626822402   [0.28459507, -0.07167025, 0.17930306, -0.29999...  ...   \n",
       "...                                                       ...  ...   \n",
       "2011621972                                                NaN  ...   \n",
       "2011622024                                                NaN  ...   \n",
       "2011622065                                                NaN  ...   \n",
       "2011626864                                                NaN  ...   \n",
       "2011632199                                                NaN  ...   \n",
       "\n",
       "                                                         d_42   \n",
       "624531411   [0.18155344, 0.026362767, -0.01475883, -0.2147...  \\\n",
       "625340088   [0.24319527, 0.12634419, -0.05570019, -0.18991...   \n",
       "625805682   [0.18210159, 0.063631855, 0.05955499, -0.32273...   \n",
       "626662493   [0.15025625, 0.0521947, -0.026349314, -0.17327...   \n",
       "626822402   [0.34554872, -0.114436746, 0.16829908, -0.2782...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_43   \n",
       "624531411   [0.0069437977, -0.09799223, -0.02816795, -0.23...  \\\n",
       "625340088   [0.12861286, 0.009207115, -0.063367575, -0.198...   \n",
       "625805682   [0.057935737, -0.034007467, 0.08288933, -0.324...   \n",
       "626662493   [0.11670811, 0.030976295, -0.02641234, -0.1190...   \n",
       "626822402   [0.25267428, -0.080995634, 0.17711401, -0.2627...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_44   \n",
       "624531411   [0.18892401, 0.041114308, -0.00097465096, -0.1...  \\\n",
       "625340088   [0.24438602, 0.14896263, -0.07208059, -0.14055...   \n",
       "625805682   [0.21283509, 0.080757335, 0.084314525, -0.2392...   \n",
       "626662493   [0.19017154, 0.094812796, -0.003392328, -0.117...   \n",
       "626822402   [0.3340537, -0.093892336, 0.1561747, -0.314642...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_45   \n",
       "624531411   [0.11469094, -0.015334345, 0.006475803, -0.087...  \\\n",
       "625340088   [0.1749304, 0.08700106, -0.05070314, -0.066946...   \n",
       "625805682   [0.099942975, -0.049863294, 0.13453224, -0.256...   \n",
       "626662493   [0.13538006, 0.04384046, 0.006757291, -0.05630...   \n",
       "626822402   [0.3147732, -0.065012425, 0.17388539, -0.25686...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_46   \n",
       "624531411   [0.027374564, -0.08158906, -0.01762917, -0.206...  \\\n",
       "625340088   [0.100104034, -0.02964319, -0.0711903, -0.2004...   \n",
       "625805682   [0.046176944, -0.0769093, 0.06805101, -0.29428...   \n",
       "626662493   [0.07334437, -0.024985045, -0.021543493, -0.13...   \n",
       "626822402   [0.29047766, -0.05335179, 0.18333776, -0.34369...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_47   \n",
       "624531411   [0.04705087, -0.065758094, -0.018019354, -0.21...  \\\n",
       "625340088   [0.13491955, 0.01794957, -0.067108504, -0.1916...   \n",
       "625805682   [0.037154716, -0.05500753, 0.088356555, -0.317...   \n",
       "626662493   [0.097782776, 0.006623201, -0.026629627, -0.12...   \n",
       "626822402   [0.2530854, -0.07009541, 0.18177888, -0.267674...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_48   \n",
       "624531411   [0.3474198, 0.15047382, 0.0039090053, -0.13961...  \\\n",
       "625340088   [0.41909015, 0.33678198, -0.07781066, -0.12629...   \n",
       "625805682   [0.33445185, 0.20716941, 0.06621084, -0.234082...   \n",
       "626662493   [0.3373683, 0.24063022, -0.0021311226, -0.1236...   \n",
       "626822402   [0.3673926, -0.15189306, 0.14653346, -0.250014...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_49   \n",
       "624531411   [0.11787519, -0.0064049475, -0.0025091413, -0....  \\\n",
       "625340088   [0.17230125, 0.06469397, -0.08423577, -0.16590...   \n",
       "625805682   [0.07703457, -0.032216277, 0.1353079, -0.22812...   \n",
       "626662493   [0.15725388, 0.042757872, -0.008270113, -0.101...   \n",
       "626822402   [0.27901053, -0.060020022, 0.20105505, -0.2875...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_50   \n",
       "624531411   [0.069682136, -0.054890573, -0.011223326, -0.1...  \\\n",
       "625340088   [0.15537813, 0.036530755, -0.06381854, -0.1704...   \n",
       "625805682   [0.06902366, -0.051700268, 0.06834428, -0.3177...   \n",
       "626662493   [0.12123768, 0.029323883, -0.025152106, -0.115...   \n",
       "626822402   [0.2838174, -0.074696735, 0.17902729, -0.29193...   \n",
       "...                                                       ...   \n",
       "2011621972                                                NaN   \n",
       "2011622024                                                NaN   \n",
       "2011622065                                                NaN   \n",
       "2011626864                                                NaN   \n",
       "2011632199                                                NaN   \n",
       "\n",
       "                                                         d_51  \n",
       "624531411   [-0.011351064, -0.100169934, -0.034848228, -0....  \n",
       "625340088   [0.02809963, -0.08056283, -0.07836892, -0.2682...  \n",
       "625805682   [0.03009884, -0.06154553, 0.08346843, -0.34348...  \n",
       "626662493   [0.022587577, -0.067165665, -0.03826805, -0.19...  \n",
       "626822402   [0.25677127, -0.058577746, 0.19382006, -0.2792...  \n",
       "...                                                       ...  \n",
       "2011621972                                                NaN  \n",
       "2011622024                                                NaN  \n",
       "2011622065                                                NaN  \n",
       "2011626864                                                NaN  \n",
       "2011632199                                                NaN  \n",
       "\n",
       "[117310 rows x 52 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002dbdf1-0b3b-4f9f-874c-375e13b2f82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-articleclassifier [Python]",
   "language": "python",
   "name": "conda-env-.conda-articleclassifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
